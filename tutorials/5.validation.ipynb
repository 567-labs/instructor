{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a01f3ac-5306-4a1b-9e47-a5d254bce93a",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc78ac-ed6d-49e3-b71b-fb2fb25f16a8",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**What is a validation**\n",
    "\n",
    "Validation is the backbone of reliable software. In escence, validation means checking that the results of a given function correspond to what we expect as output from that function. Traditionally, all validation was deterministic and rule based (i.e. 'output must not be larger than') but with the advent of LLM's we can also incorporate probabilistic validation into our stack (i.e. 'answer cannot contain aggressive language'). This new type of validation has been traditionally refered to with the fancy name of 'guardrail' although if we dig a bit we will find its just another type of validation - using LLM's instead of rules to flag the response.\n",
    "\n",
    "In instructor, we treat all validation as... validation. You can do rule-based validation, probabilistic validation or both - all under one and the same framework. For this we will make extensive use of Pydantic's powerful [validators](https://docs.pydantic.dev/latest/concepts/validators/#field-validators) functionality.\n",
    "\n",
    "Essentially a validator looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb6258-b03a-4621-8a73-29056a20ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_function(value):\n",
    "    if condition(value):\n",
    "        raise ValueError(\"Value is not valid\")\n",
    "    return mutation(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d41e88-4629-4a44-a701-2bcdb297f090",
   "metadata": {},
   "source": [
    "It consists of three basic steps:\n",
    "1. We check if a value corresponds to a certain condition\n",
    "2. If not we raise an error with an optional retry\n",
    "3. If it does we return the value or a mutation of the value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417fafe5-4616-4372-b9e9-78e89afff536",
   "metadata": {},
   "source": [
    "**Validation applications**\n",
    "\n",
    "Validators will enable us to have a tighter control on how our applications work. Fundamentally, we will be targetting the main disadvantage of LLM's compared to their more traditional counterpart: their stochasticity and unpredictability.\n",
    "\n",
    "Some straightforward examples of this are:\n",
    "- Flagging outputs that contain forbidden words that are present in a blacklist\n",
    "- Flagging outputs that have an undesired tone (racism, violence etc.)\n",
    "\n",
    "But if we get creative we can move into complex, non-trivial applications:\n",
    "- Making sure that a citation actually is obtained directly from the provided content\n",
    "- Ensuring that the model's answer follows after a given context has been provided\n",
    "- Checking that the syntax of an SQL query is valid before running it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2104b-7eed-4619-a47d-c3d197f9d483",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94449ab-50a9-4325-972c-f64fcdadee00",
   "metadata": {},
   "source": [
    "As always, we're going to use the [`instructor`](https://github.com/jxnl/instructor) library to help us in integrating these powerful validators. `instructor` will handle all the output parsing and validation plus the automatic retries to get a compliant response. This will make it very easy for us devs to add new validation logic, without paying unnecessary overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d1279f-3db4-4b3c-9a92-8c558c43488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install instructor -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa2c503-82f8-4735-aae3-373b55fb1064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor \n",
    "from openai import OpenAI\n",
    "\n",
    "client = instructor.patch(OpenAI())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd244f-d59c-4431-be2d-aa356a6fefa0",
   "metadata": {},
   "source": [
    "## Rule-based examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3494e664-c5b3-42ea-9c19-aa301a041bdb",
   "metadata": {},
   "source": [
    "Let's see how we can use some deterministic validation examples. These examples are deterministic because the logic for this validation is entirely rule based and the same input will always result in the same output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717ecefd-0355-4ba4-a642-95d281b0f075",
   "metadata": {},
   "source": [
    "### Keyword blacklist\n",
    "#### Example: flagging for violence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9008aa-59e9-4c41-8756-eec0ddc30597",
   "metadata": {},
   "source": [
    "For starters, we don't want it to engage in topics that contain explicit violence so we will stop it from returning an answer containing words from a violence blacklist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11459241-bf5e-4bfc-89bb-2562cf92dd62",
   "metadata": {},
   "source": [
    "For this we can use a field_validator, which will check if a given field complies with our validation logic - in this case the user message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59330d7d-082a-4240-98c4-eaee18f02728",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = {\n",
    "    \"rob\",\n",
    "    \"steal\",\n",
    "    \"hurt\",\n",
    "    \"kill\",\n",
    "    \"attack\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bb87f47-db98-4f1d-80cb-ad5f39df8793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for UserMessage\n",
      "message\n",
      "  Value error, `hurt` was found in the message `I want to hurt him` [type=value_error, input_value='I want to hurt him', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/value_error\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, ValidationError, field_validator\n",
    "from pydantic.fields import Field\n",
    "\n",
    "\n",
    "class UserMessage(BaseModel):\n",
    "    message: str\n",
    "\n",
    "    @field_validator('message')\n",
    "    def message_cannot_have_blacklisted_words(cls, v: str) -> str:\n",
    "        for word in v.split(): \n",
    "            if word.lower() in blacklist:\n",
    "                raise ValueError(f\"`{word}` was found in the message `{v}`\")\n",
    "        return v\n",
    "\n",
    "try:\n",
    "    UserMessage(message=\"Hey, what should I do with someone that bullies me about my health practices?\")\n",
    "    UserMessage(message=\"I want to hurt him\")\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3a638-c9c9-44cd-bcd0-ad1a39f448db",
   "metadata": {},
   "source": [
    "### Outsourcing validation\n",
    "#### Example: filter using OpenAI Moderation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d0b816-7ec8-42b0-9b91-c9aab382c960",
   "metadata": {},
   "source": [
    "We would probably want to take this further and say we want to flag any answer that is hateful, contains harrassment etc. Thankfully, openai provides a moderation endpoint which covers all these use cases and is free to use when using openai models. \n",
    "\n",
    "Let's see how we can implement this with instructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82521112-5301-4442-acce-82b495bd838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserMessage(BaseModel):\n",
    "    message: str\n",
    "\n",
    "    @field_validator('message')\n",
    "    def message_must_comply_with_openai_mod(cls, v: str) -> str:\n",
    "        response = client.moderations.create(input=v)\n",
    "        out = response.results[0]\n",
    "        cats = dict(out.categories)\n",
    "        if out.flagged:\n",
    "            raise ValueError(f\"`{v}` was flagged for {[i for i in cats if cats[i]]}\")\n",
    "        \n",
    "        return v "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90542190-a4f2-4242-8261-2f0ace323022",
   "metadata": {},
   "source": [
    "Now we have a more comprehensive flagging for violence and we can actually outsource the moderation of our messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54a9de1b-c6e7-4a5f-854c-506083a06a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for UserMessage\n",
      "message\n",
      "  Value error, `I want to make him suffer the consequences` was flagged for ['harassment', 'violence'] [type=value_error, input_value='I want to make him suffer the consequences', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/value_error\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    UserMessage(message=\"What should I do with someone that bullies me about my health practices?\")\n",
    "    UserMessage(message=\"I want to make him suffer the consequences\")\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138f9f8-495a-4a09-96a0-c71d01561855",
   "metadata": {},
   "source": [
    "And we get flagging for other topics like religion, race etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "feb77670-afd7-4947-89f8-a9446f6fb12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for UserMessage\n",
      "message\n",
      "  Value error, `I will mock his religion` was flagged for ['harassment'] [type=value_error, input_value='I will mock his religion', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/value_error\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    UserMessage(message=\"What should I do with someone that bullies me about my health practices?\")\n",
    "    UserMessage(message=\"I will mock his religion\")\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa717d5-0d97-49cd-a3a8-d3a0bb44645b",
   "metadata": {},
   "source": [
    "The point here is how easily we could change from using keywords to using an external api for moderation - with `field_validators`, its a function edit away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f122b-22c9-440e-99cf-2e594b3df99b",
   "metadata": {},
   "source": [
    "### Text structure filtering\n",
    "#### Example: filtering very long messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b1164-4bd5-4943-b9ab-2edec00d4f7d",
   "metadata": {},
   "source": [
    "We can also flag based on other aspects of the input text. Let's say we don't want the assistant to return very long texts because the user might lose interest and disengage from the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45ffdbd4-deae-4a46-9637-1b5339904f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, ValidationError, field_validator\n",
    "from pydantic.fields import Field\n",
    "\n",
    "\n",
    "class AssistantMessage(BaseModel):\n",
    "    message: str\n",
    "\n",
    "    @field_validator('message')\n",
    "    def message_must_be_short(cls, v: str) -> str:\n",
    "        if len(v.split())>=100:\n",
    "            raise ValueError(f\"Text was flagged for being longer than 100 words.\")\n",
    "        \n",
    "        return v     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66430dc5-b78c-45e2-a53b-ddc392b20583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for AssistantMessage\n",
      "message\n",
      "  Value error, Text was flagged for being longer than 100 words. [type=value_error, input_value=\"\\n    Certainly! Lorem i... on the actual content.\", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/value_error\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    AssistantMessage(message=\"\"\"\n",
    "    Certainly! Lorem ipsum is a placeholder text commonly used in the printing and typesetting industry. Here's a sample of Lorem ipsum text:\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam euismod velit vel tellus tempor, non viverra eros iaculis. Sed vel nisl nec mauris bibendum tincidunt. Vestibulum sed libero euismod, eleifend tellus id, laoreet elit. Donec auctor arcu ac mi feugiat, vel lobortis justo efficitur. Fusce vel odio vitae justo varius dignissim. Integer sollicitudin mi a justo bibendum ultrices. Quisque id nisl a lectus venenatis luctus.\n",
    "\n",
    "Please note that Lorem ipsum text is a nonsensical Latin-like text used as a placeholder for content, and it has no specific meaning. It's often used in design and publishing to demonstrate the visual aspects of a document without focusing on the actual content.\"\"\"\n",
    "                    )\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050e72fe-4b13-4002-a1d0-94f7b88b784b",
   "metadata": {},
   "source": [
    "### Validating answer from context\n",
    "#### Example: avoiding hallucination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f2869e-c8a3-4b93-82e7-55eb70930900",
   "metadata": {},
   "source": [
    "When using external knowledge bases we want to make sure that the agent is using the provided context to answer and is not inventing the answer itself. This is very easy to do with both validators as we will show in the following example where we will check if the provided citation is actually included in the text chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "638fc368-5cf7-4ae7-9d3f-efea1b84eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import ValidationInfo,BaseModel,field_validator\n",
    "\n",
    "class AnswerWithCitation(BaseModel):\n",
    "    answer: str\n",
    "    citation: str\n",
    "\n",
    "    @field_validator('citation')\n",
    "    @classmethod\n",
    "    def citation_exists(cls, v: str, info: ValidationInfo): \n",
    "        context = info.context\n",
    "        if context:\n",
    "            context = context.get('text_chunk')\n",
    "            if v not in context:\n",
    "                raise ValueError(f\"Citation `{v}` not found in text chunks\")\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f3030b6-e6cf-45bf-a366-12de996fea40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for AnswerWithCitation\n",
      "citation\n",
      "  Value error, Citation `Blueberries contain high levels of protein` not found in text chunks [type=value_error, input_value='Blueberries contain high levels of protein', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.4/v/value_error\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    AnswerWithCitation.model_validate(\n",
    "        {\"answer\": \"Blueberries are packed with protein\", \"citation\": \"Blueberries contain high levels of protein\"},\n",
    "        context={\"text_chunk\": \"Blueberries are very rich in antioxidants\"}, \n",
    "    )\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e54533-3304-4fa0-9828-9591d5dcdefd",
   "metadata": {},
   "source": [
    "## LLM-based examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907df5b-472f-45ac-9181-45235e3cd0c3",
   "metadata": {},
   "source": [
    "But in some cases we need more complex validation than rule-based validation allows. What we need is probabilistic validation and we will handle this using LLMs as an integral part of our validation workflow. \n",
    "\n",
    "Thankfully, `instructor` provides a handy `llm_validator` utility which we can use by simply specifying the directive we want it to follow.\n",
    "\n",
    "Let's see a few interesting use cases that LLM's enable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd43d4c3-930a-4b3a-aded-3ad7308454ba",
   "metadata": {},
   "source": [
    "### Content-based filtering\n",
    "#### Example: always keeping agent on topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2f9aee-4dd5-4ee7-80a2-3770e454e0f6",
   "metadata": {},
   "source": [
    "Let's say we want an agent that helps us improve our health by answering questions and suggesting specific practices daily. We want to make sure the agent does not answer about any other topic because the knowledge base does not contain information about other topics and it will be prone to hallucinate. The process for doing this is very similar as above, but this time we will add an LLM in our validator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "971489ce-2a4b-4db3-8fbf-d9c6cc15d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instructor import llm_validator\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from typing import Annotated, Optional\n",
    "from pydantic import Field\n",
    "from pydantic.functional_validators import AfterValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf00cad-c4c0-49dd-9be5-fb02338a5a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssistantMessage(BaseModel):\n",
    "    message: Annotated[str, AfterValidator(llm_validator(\"don't talk about any other topic except health best practices and topics\"))]\n",
    "\n",
    "try:\n",
    "    AssistantMessage(message=\"I would suggest you to visit Sicily as they say it is very nice in winter.\")\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce5a7a-024e-4742-a124-fe51973df5f2",
   "metadata": {},
   "source": [
    "Great! Now we can be sure that our model will only speak about what it knows about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec4afa-0be7-469e-93c0-5c729a06d4fc",
   "metadata": {},
   "source": [
    "### Content-based filtering with more than one variable\n",
    "#### Example: checking agent thinking logic with CoT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d915b-f332-48f3-a75e-6e1cd6d12075",
   "metadata": {},
   "source": [
    "Another nice use case for probabilistic validation is to validate the agent's thinking process and see if it makes sense before returning. When using [chain of thought](https://learnprompting.org/docs/intermediate/chain_of_thought#:~:text=Chain%20of%20Thought%20(CoT)%20prompting,CoT%20(Wei%20et%20al.)), we want the models to be able to think in steps and answer after following through on its thinking logic. If there's any errors in the logic, then the result will not be correct. Thankfully, its easy to check this in a similar way as we did in the previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c95242-6517-4ce2-aa99-4437db658057",
   "metadata": {},
   "source": [
    "Here we will use Pydantic's [model_validator](https://docs.pydantic.dev/latest/concepts/validators/#model-validators) which allows us to apply validation over all the properties of the `AIResponse` at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211816e-c0fa-462d-acd0-7ab5a8096eb6",
   "metadata": {},
   "source": [
    "For this, we will define a `Validation` class which will contain the desired format of the output of our llm call (this was handled by `llm_validator` in the previous example. \n",
    "\n",
    "This class is very straighforward: we will ask it to tell us whether the chain of thought is valid and if no, why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65340b8c-2ea3-4457-a6d4-f0e652c317b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validation(BaseModel):\n",
    "    is_valid: bool = Field(..., description=\"Whether the value is valid based on the rules or contradictory\")\n",
    "    error_message: Optional[str] = Field(..., description=\"The error message if the value is not valid, to be used for re-asking the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9ab3804-6962-4a48-83da-1f8360d8379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_chain_of_thought(values):\n",
    "    chain_of_thought = values[\"chain_of_thought\"]\n",
    "    answer = values[\"answer\"]\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a validator. Determine if the value is valid for the statement. If it is not, explain why.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Verify that `{answer}` follows the chain of thought: {chain_of_thought}\",\n",
    "            },\n",
    "        ],\n",
    "        # this comes from client = instructor.patch(OpenAI())\n",
    "        response_model=Validation,\n",
    "    )\n",
    "    print(resp)\n",
    "    if not resp.is_valid:\n",
    "        raise ValueError(resp.error_message)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fbc9887a-df0d-4a4b-9ef5-ea450701d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, model_validator\n",
    "from typing import Any\n",
    "\n",
    "class AIResponse(BaseModel):\n",
    "    chain_of_thought: str\n",
    "    answer: str\n",
    "\n",
    "    @model_validator(mode='before')\n",
    "    @classmethod\n",
    "    def chain_of_thought_makes_sense(cls, data: Any) -> Any:\n",
    "        # here we assume data is the dict representation of the model\n",
    "        # since we use 'before' mode.\n",
    "        return validate_chain_of_thought(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a38f2b28-f5b9-4a44-bfe5-9735726ec57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_valid=True error_message=None\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    resp = AIResponse(\n",
    "        chain_of_thought=\"The user is diabetic.\", answer=\"The user shouldn't need to care about sugar blood levels.\"\n",
    "        # chain_of_thought=\"2+2=4\", answer=\"grass is green.\"\n",
    ")\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbbaa11-32d2-4772-bc31-18d1d6d6c919",
   "metadata": {},
   "source": [
    "## Putting validation to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e642d9-0d20-4231-a694-baa0ea03f147",
   "metadata": {},
   "source": [
    "How can we integrate any of these examples when using the openai api? It is very easy with `instructor`: after patching the openai client, we just need to specify a `response_model` and all the validation will happen under the hood. \n",
    "\n",
    "We can even set a max number of retries so that if the llm returns a wrong result, we give it a few more chances to get it right by sending the original answer plus the reason why it got rejected. We can do this by just adding `max_retries` when calling the `openai` client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97f544e7-2552-465c-89a9-a4820f00d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HealthAnswer(BaseModel):\n",
    "    answer: Annotated[str, AfterValidator(llm_validator(\"don't talk about any other topic except health best practices and topics\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbd8aff1-4ad7-49d2-87f0-47ef155192ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for HealthAnswer\nanswer\n  Assertion failed, The statement is not related to health best practices or topics. [type=assertion_error, input_value=\"Unfortunately, I don't h... that suits your needs.\", input_type=str]\n    For further information visit https://errors.pydantic.dev/2.4/v/assertion_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhich is the best headphone brand for producing music?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHealthAnswer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pampa-labs/lib/python3.10/site-packages/instructor/patch.py:168\u001b[0m, in \u001b[0;36mwrap_chatcompletion.<locals>.new_chatcompletion_sync\u001b[0;34m(response_model, validation_context, max_retries, *args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_chatcompletion_sync\u001b[39m(\n\u001b[1;32m    161\u001b[0m     response_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    166\u001b[0m ):\n\u001b[1;32m    167\u001b[0m     response_model, new_kwargs \u001b[38;5;241m=\u001b[39m handle_response_model(response_model, kwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     response, error \u001b[38;5;241m=\u001b[39m \u001b[43mretry_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error)\n",
      "File \u001b[0;32m~/.virtualenvs/pampa-labs/lib/python3.10/site-packages/instructor/patch.py:134\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict)\u001b[0m\n\u001b[1;32m    132\u001b[0m retries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m max_retries:\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.virtualenvs/pampa-labs/lib/python3.10/site-packages/instructor/patch.py:119\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, validation_context, args, kwargs, max_retries, strict)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     response \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 119\u001b[0m         \u001b[43mprocess_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationError, JSONDecodeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    125\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pampa-labs/lib/python3.10/site-packages/instructor/patch.py:61\u001b[0m, in \u001b[0;36mprocess_response\u001b[0;34m(response, response_model, validation_context, strict)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Processes a OpenAI response with the response model, if available\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mIt can use `validation_context` and `strict` to validate the response\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03mvia the pydantic model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    strict (bool, optional): Whether to use strict json parsing. Defaults to None.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     model\u001b[38;5;241m.\u001b[39m_raw_response \u001b[38;5;241m=\u001b[39m response\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.virtualenvs/pampa-labs/lib/python3.10/site-packages/instructor/function_calls.py:196\u001b[0m, in \u001b[0;36mOpenAISchema.from_response\u001b[0;34m(cls, completion, throw_error, validation_context, strict)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the function from the response of an openai chat completion\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    cls (OpenAISchema): An instance of the class\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m message \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_call\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/pampa-labs/lib/python3.10/site-packages/pydantic/main.py:530\u001b[0m, in \u001b[0;36mBaseModel.model_validate_json\u001b[0;34m(cls, json_data, strict, context)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    529\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for HealthAnswer\nanswer\n  Assertion failed, The statement is not related to health best practices or topics. [type=assertion_error, input_value=\"Unfortunately, I don't h... that suits your needs.\", input_type=str]\n    For further information visit https://errors.pydantic.dev/2.4/v/assertion_error"
     ]
    }
   ],
   "source": [
    "model = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Which is the best headphone brand for producing music?\"},\n",
    "    ],\n",
    "    response_model=HealthAnswer,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c07b8b-ba6d-4e5d-a26c-ba72ca7d4f22",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pampa-labs",
   "language": "python",
   "name": "pampa-labs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
