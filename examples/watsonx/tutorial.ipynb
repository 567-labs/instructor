{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append( '/Users/andreswagner/Documents/GitHub/instructor' )\n",
    "module_path = os.path.abspath(os.path.join('/Users/andreswagner/Documents/GitHub/instructor'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started in Minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Instructor with a single command:\n",
    "\n",
    "```bash\n",
    "pip install -U instructor\n",
    "pip install ibm-watsonx-ai\n",
    "```\n",
    "\n",
    "Now, let's see Instructor in action with a simple example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "import openai\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import logging\n",
    "\n",
    "import os\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'messages': [{'role': 'user', 'content': 'Watson is only 3 years old'}], 'tools': [{'type': 'function', 'function': {'name': 'UserInfo', 'description': 'Correctly extracted `UserInfo` with all the required parameters with correct types', 'parameters': {'properties': {'name': {'title': 'Name', 'type': 'string'}, 'age': {'title': 'Age', 'type': 'integer'}}, 'required': ['age', 'name'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'UserInfo'}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\", \n",
    "            \"function\": {\n",
    "                \"name\": \"UserInfo\", \n",
    "                \"description\": \"Correctly extracted `UserInfo` with all the required parameters with correct types\", \n",
    "                \"parameters\": {\n",
    "                    \"properties\": {\n",
    "                        \"name\": {\"title\": \"Name\", \"type\": \"string\"}, \n",
    "                        \"age\": {\"title\": \"Age\", \"type\": \"integer\"}\n",
    "                    }, \n",
    "                    \"required\": [\"age\", \"name\"], \n",
    "                    \"type\": \"object\"\n",
    "                }\n",
    "            }\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful customer support assistant. Use the supplied tools to assist the user.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Watson is only 3 years old\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {'role': 'system', 'content': 'You are a helpful customer support assistant. Use the supplied tools to assist the user.'}, \n",
    "    {'role': 'user', 'content': 'Watson is only 123 years old'}]\n",
    "\n",
    "tool_choice_option = 'auto'\n",
    "\n",
    "tools=[\n",
    "    {'type': 'function', \n",
    "     'function': {\n",
    "         'name': 'UserInfo', \n",
    "         'description': 'Correctly extracted `UserInfo` with all the required parameters with correct types', \n",
    "         'parameters': {\n",
    "             'properties': {\n",
    "                 'name': {'title': 'Name', 'type': 'string'}, \n",
    "                 'age': {'title': 'Age', 'type': 'integer'}\n",
    "                }, \n",
    "            'required': ['age', 'name'], \n",
    "            'type': 'object'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "tool_choice= {\"type\": \"function\", \"function\": {\"name\": \"UserInfo\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'index': 0, 'message': {'role': 'assistant', 'tool_calls': [{'id': 'chatcmpl-tool-d5370601228548debf98ab16ed2af671', 'type': 'function', 'function': {'name': 'UserInfo', 'arguments': '{\"age\": 123, \"name\": \"Watson\"}'}}]}, 'finish_reason': 'tool_calls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\n",
    "        'role': 'user', \n",
    "        'content': 'You are a world class assistant to answer questions with correct and exact citations based on a given CONTEXT.'\n",
    "    }, \n",
    "    {\n",
    "        'role': 'assistant', \n",
    "        'content': \n",
    "        \"\"\"I have the following context uppon I have to base my answers. \n",
    "        CONTEXT: 'My name is Jason Liu, and I grew up in Toronto Canada but I was born in China. \n",
    "        I went to an arts high school but in university I studied Computational Mathematics and physics.\n",
    "        As part of coop I worked at many companies including Stitchfix, Facebook.\n",
    "        I also started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.'\n",
    "        \"\"\"\n",
    "    }, \n",
    "    {\n",
    "        'role': 'user', \n",
    "        'content': 'Question: What did Jason Liu do during college?'\n",
    "    }\n",
    "]\n",
    "tool_choice_option = 'auto', \n",
    "tools= [{\n",
    "    'type': 'function', \n",
    "    'function': {\n",
    "        'name': 'QuestionAnswer', \n",
    "        'description': 'Correctly extracted `QuestionAnswer` with all the required parameters with correct types', \n",
    "        'parameters': {\n",
    "            '$defs': {\n",
    "                'Fact': {\n",
    "                    'properties': {\n",
    "                        'fact': {'title': 'Fact', 'type': 'string'}, \n",
    "                        'substring_quote': {\n",
    "                            'items': {'type': 'string'}, \n",
    "                            'title': 'Substring Quote', 'type': 'array'\n",
    "                        }\n",
    "                    }, \n",
    "                    'required': ['fact', 'substring_quote'], \n",
    "                    'title': 'Fact', \n",
    "                    'type': 'object'\n",
    "                }\n",
    "            }, \n",
    "            'properties': {\n",
    "                'question': {'title': 'Question', 'type': 'string'}, \n",
    "                'answer': {\n",
    "                    'items': {'$ref': '#/$defs/Fact'}, \n",
    "                    'title': 'Answer', 'type': 'array'\n",
    "                }\n",
    "            }, \n",
    "            'required': ['answer', 'question'], \n",
    "            'type': 'object'\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "tool_choice = {\n",
    "    'type': 'function', \n",
    "    'function': {'name': 'QuestionAnswer'}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'index': 0, 'message': {'role': 'assistant', 'content': '[TOOL_CALLS] [{\"name\": \"QuestionAnswer\", \"arguments\": {\"question\": \"What did Jason Liu do during college?\", \"answer\": [{\"fact\": \"Jason Liu studied at the University of Waterloo\", \"substring_quote\": [\"University of Waterloo\"]}, {\"fact\": \"He studied Computational Mathematics and Physics\", \"substring_quote\": [\"Computational Mathematics and physics\"]}, {\"fact\": \"He started the Data Science Club\", \"substring_quote\": [\"Data Science club\"]}, {\"fact\": \"He was the president of the club for 2 years\", \"substring_quote\": [\"2 years\"]}]}}]'}, 'finish_reason': 'stop'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat import ChatCompletion\n",
    "completion={'id': 'chat-380be2eab62f4f51b109006aa4c332bc', 'model_id': 'mistralai/mistral-large', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '[TOOL_CALLS] [{\"name\": \"QuestionAnswer\", \"arguments\": {\"answer\": [{\"fact\": \"I started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.\", \"substring_quote\": [\"started the Data Science club\", \"was the president of the club for 2 years\"]}], \"question\": \"What did Jason Liu do during college?\"}}]'}, 'finish_reason': 'stop'}], 'created': 1730067296, 'model_version': '2.0.0', 'created_at': '2024-10-27T22:14:58.188Z', 'usage': {'completion_tokens': 90, 'prompt_tokens': 369, 'total_tokens': 459}, 'system': {'warnings': [{'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.', 'id': 'disclaimer_warning', 'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'}, {'message': \"The value of 'max_tokens' for this model was set to value 1024\", 'id': 'unspecified_max_token', 'additional_properties': {'limit': 0, 'new_value': 1024, 'parameter': 'max_tokens', 'value': 0}}]}}\n",
    "completion[\"model\"]=completion[\"model_id\"]\n",
    "completion[\"object\"]=\"chat.completion\" \n",
    "completion= ChatCompletion(**completion)\n",
    "completion.choices[0].message.content=completion.choices[0].message.content.replace(\"[TOOL_CALLS]\",\"\")\n",
    "completion.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}\n",
    "]\n",
    "generated_response = model.chat(messages=messages)\n",
    "\n",
    "# Print all response\n",
    "# print(generated_response)\n",
    "\n",
    "# Print only content\n",
    "#print(generated_response['choices'][0]['message']['content'])\n",
    "\n",
    "# Print only content\n",
    "print(generated_response['choices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\n",
    "        'role': 'user', \n",
    "        'content': 'You are a world class assistant to answer questions with correct and exact citations based on a given CONTEXT.'\n",
    "    }, \n",
    "    {\n",
    "        'role': 'assistant', \n",
    "        'content': \n",
    "        \"\"\"I have the following context uppon I have to base my answers. \n",
    "        CONTEXT: 'My name is Jason Liu, and I grew up in Toronto Canada but I was born in China. \n",
    "        I went to an arts high school but in university I studied Computational Mathematics and physics.\n",
    "        As part of coop I worked at many companies including Stitchfix, Facebook.\n",
    "        I also started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.'\n",
    "        \"\"\"\n",
    "    }, \n",
    "    {\n",
    "        'role': 'user', \n",
    "        'content': 'Question: What did Jason Liu do during college?'\n",
    "    }\n",
    "]\n",
    " \n",
    "tools= [{\n",
    "    'type': 'function', \n",
    "    'function': {\n",
    "        'name': 'QuestionAnswer', \n",
    "        'description': 'Correctly extracted `QuestionAnswer` with all the required parameters with correct types', \n",
    "        'parameters': {\n",
    "            '$defs': {\n",
    "                'Fact': {\n",
    "                    'properties': {\n",
    "                        'fact': {'title': 'Fact', 'type': 'string'}, \n",
    "                        'substring_quote': {\n",
    "                            'items': {'type': 'string'}, \n",
    "                            'title': 'Substring Quote', 'type': 'array'\n",
    "                        }\n",
    "                    }, \n",
    "                    'required': ['fact', 'substring_quote'], \n",
    "                    'title': 'Fact', \n",
    "                    'type': 'object'\n",
    "                }\n",
    "            }, \n",
    "            'properties': {\n",
    "                'question': {'title': 'Question', 'type': 'string'}, \n",
    "                'answer': {\n",
    "                    'items': {'$ref': '#/$defs/Fact'}, \n",
    "                    'title': 'Answer', 'type': 'array'\n",
    "                }\n",
    "            }, \n",
    "            'required': ['answer', 'question'], \n",
    "            'type': 'object'\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "tool_choice = {\n",
    "    'type': 'function', \n",
    "    'function': {'name': 'QuestionAnswer'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    model_id='meta-llama/llama-3-70b-instruct', #'mistralai/mistral-large',\n",
    "    params={\"tool_choice\":'auto'},\n",
    "    credentials=Credentials(\n",
    "        api_key = os.environ.get(\"WATSONX_API_KEY\"),\n",
    "        url = os.environ.get(\"WATSONX_URL\")),\n",
    "    project_id= os.environ.get(\"WATSONX_PROJECT_ID\")\n",
    ")\n",
    "\n",
    "completion = model.chat(\n",
    "    messages=messages,  \n",
    "    tools=tools,\n",
    "    tool_choice=tool_choice\n",
    ")\n",
    "# Print all response\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired output structure\n",
    "class UserInfo(BaseModel):\n",
    "    name: str\n",
    "    age: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch the OpenAI client\n",
    "\n",
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "# Set logging to DEBUG\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=UserInfo,\n",
    "    max_retries=1,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"John Doe is 30 years old.\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_info.name)\n",
    "#> John Doe\n",
    "print(user_info.age)\n",
    "#> 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch the Watsonx client\n",
    "import logging\n",
    "\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "\n",
    "\n",
    "#from instructor import from_watsonx\n",
    "from instructor.function_calls import Mode\n",
    "\n",
    "\n",
    "client = Model(\n",
    "    model_id='mistralai/mistral-large',#'meta-llama/llama-3-70b-instruct',\n",
    "    params={\"tool_choice\":'auto'},\n",
    "    credentials=Credentials(\n",
    "        api_key = os.environ.get(\"WATSONX_API_KEY\"),\n",
    "        url = os.environ.get(\"WATSONX_URL\")),\n",
    "    project_id= os.environ.get(\"WATSONX_PROJECT_ID\")\n",
    ")\n",
    "\n",
    "# Patch the client with Watsonx\n",
    "instructor_client=instructor.from_watsonx(\n",
    "    client=client,\n",
    "    mode=instructor.Mode.WATSONX_TOOLS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging to DEBUG\n",
    "# tool_choice_option=\"auto\",\n",
    "\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "user_info = instructor_client.messages.create(\n",
    "    response_model=UserInfo,\n",
    "    max_retries=3,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Satyam is only 3 years old\"}],\n",
    ")\n",
    "print(user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_info.name)\n",
    "print(user_info.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_block = \"\"\"\n",
    "In our recent online meeting, participants from various backgrounds joined to discuss the upcoming tech conference. The names and contact details of the participants were as follows:\n",
    "\n",
    "- Name: John Doe, Email: johndoe@email.com, Twitter: @TechGuru44\n",
    "- Name: Jane Smith, Email: janesmith@email.com, Twitter: @DigitalDiva88\n",
    "- Name: Alex Johnson, Email: alexj@email.com, Twitter: @CodeMaster2023\n",
    "\n",
    "During the meeting, we agreed on several key points. The conference will be held on March 15th, 2024, at the Grand Tech Arena located at 4521 Innovation Drive. Dr. Emily Johnson, a renowned AI researcher, will be our keynote speaker.\n",
    "\n",
    "The budget for the event is set at $50,000, covering venue costs, speaker fees, and promotional activities. Each participant is expected to contribute an article to the conference blog by February 20th.\n",
    "\n",
    "A follow-up meetingis scheduled for January 25th at 3 PM GMT to finalize the agenda and confirm the list of speakers.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Get the information about the meeting and the users {text_block}\",\n",
    "    },\n",
    "]\n",
    "generated_response = client.chat_stream(messages=messages)\n",
    "\n",
    "for chunk in generated_response:\n",
    "    print(chunk['choices'][0]['delta'].get('content', ''), end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "#from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "#from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes, DecodingMethods\n",
    "\n",
    "# To display example params enter\n",
    "#GenParams().get_example_values()\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    model_id='meta-llama/llama-3-70b-instruct', #'mistralai/mistral-large',\n",
    "    params={\"tool_choice\":'auto'},\n",
    "    credentials=Credentials(\n",
    "        api_key = os.environ[\"WATSONX_API_KEY\"],\n",
    "        url = \"https://us-south.ml.cloud.ibm.com\"),\n",
    "    project_id= os.environ[\"WATSONX_PROJECT_ID\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Eres un asistente útil.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quién ganó las elecciones presidenciales en Chile?\"}\n",
    "]\n",
    "generated_response = model.chat(messages=messages)\n",
    "\n",
    "# Print all response\n",
    "print(generated_response['choices'][0]['message']['content'])\n",
    "\n",
    "# Print only content\n",
    "#print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Hooks\n",
    "Instructor provides a powerful hooks system that allows you to intercept and log various stages of the LLM interaction process. Here's a simple example demonstrating how to use hooks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hook functions\n",
    "def log_kwargs(**kwargs):\n",
    "    print(f\"Function called with kwargs: {kwargs}\")\n",
    "\n",
    "def log_exception(exception: Exception):\n",
    "    print(f\"An exception occurred: {str(exception)}\")\n",
    "\n",
    "instructor_client.on(\"completion:kwargs\", log_kwargs)\n",
    "instructor_client.on(\"completion:error\", log_exception)\n",
    "\n",
    "user_info = instructor_client.messages.create(\n",
    "    tool_choice_option=\"auto\",\n",
    "    response_model=UserInfo,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Extract the user name: 'John is 20 years old'\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Name: {user_info.name}, Age: {user_info.age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "\n",
    "from instructor import Partial\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from rich.console import Console\n",
    "\n",
    "#client = instructor.from_openai(OpenAI())\n",
    "\n",
    "text_block = \"...\"\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    twitter: str\n",
    "\n",
    "\n",
    "class MeetingInfo(BaseModel):\n",
    "    users: List[User]\n",
    "    date: str\n",
    "    location: str\n",
    "    budget: int\n",
    "    deadline: str\n",
    "\n",
    "client = Model(\n",
    "    model_id='mistralai/mistral-large',#'meta-llama/llama-3-70b-instruct',\n",
    "    params={\"tool_choice\":'auto'},\n",
    "    credentials=Credentials(\n",
    "        api_key = os.environ.get(\"WATSONX_API_KEY\"),\n",
    "        url = os.environ.get(\"WATSONX_URL\")),\n",
    "    project_id= os.environ.get(\"WATSONX_PROJECT_ID\")\n",
    ")\n",
    "\n",
    "# Patch the client with Watsonx\n",
    "instructor_client=instructor.from_watsonx(\n",
    "    client=client,\n",
    "    mode=instructor.Mode.WATSONX_TOOLS,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "extraction_stream = instructor_client.messages.create( #client.chat.completions.create(\n",
    "    #model=\"gpt-4\",\n",
    "    response_model=Partial[MeetingInfo],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Get the information about the meeting and the users {text_block}\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "console = Console()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for extraction in extraction_stream:\n",
    "    obj = extraction.model_dump()\n",
    "    console.clear()\n",
    "    console.print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from rich.console import Console\n",
    "\n",
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "text_block = \"\"\"\n",
    "In our recent online meeting, participants from various backgrounds joined to discuss the upcoming tech conference. The names and contact details of the participants were as follows:\n",
    "\n",
    "- Name: John Doe, Email: johndoe@email.com, Twitter: @TechGuru44\n",
    "- Name: Jane Smith, Email: janesmith@email.com, Twitter: @DigitalDiva88\n",
    "- Name: Alex Johnson, Email: alexj@email.com, Twitter: @CodeMaster2023\n",
    "\n",
    "During the meeting, we agreed on several key points. The conference will be held on March 15th, 2024, at the Grand Tech Arena located at 4521 Innovation Drive. Dr. Emily Johnson, a renowned AI researcher, will be our keynote speaker.\n",
    "\n",
    "The budget for the event is set at $50,000, covering venue costs, speaker fees, and promotional activities. Each participant is expected to contribute an article to the conference blog by February 20th.\n",
    "\n",
    "A follow-up meetingis scheduled for January 25th at 3 PM GMT to finalize the agenda and confirm the list of speakers.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    twitter: str\n",
    "\n",
    "\n",
    "class MeetingInfo(BaseModel):\n",
    "    users: List[User]\n",
    "    date: str\n",
    "    location: str\n",
    "    budget: int\n",
    "    deadline: str\n",
    "\n",
    "\n",
    "extraction_stream = client.chat.completions.create_partial(\n",
    "    model=\"gpt-4\",\n",
    "    response_model=MeetingInfo,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Get the information about the meeting and the users {text_block}\",\n",
    "        },\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "\n",
    "console = Console()\n",
    "\n",
    "for extraction in extraction_stream:\n",
    "    obj = extraction.model_dump()\n",
    "    console.clear()\n",
    "    console.print(obj)\n",
    "\n",
    "print(extraction.model_dump_json(indent=2))\n",
    "\"\"\"\n",
    "{\n",
    "  \"users\": [\n",
    "    {\n",
    "      \"name\": \"John Doe\",\n",
    "      \"email\": \"johndoe@email.com\",\n",
    "      \"twitter\": \"@TechGuru44\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Jane Smith\",\n",
    "      \"email\": \"janesmith@email.com\",\n",
    "      \"twitter\": \"@DigitalDiva88\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Alex Johnson\",\n",
    "      \"email\": \"alexj@email.com\",\n",
    "      \"twitter\": \"@CodeMaster2023\"\n",
    "    }\n",
    "  ],\n",
    "  \"date\": \"2024-03-15\",\n",
    "  \"location\": \"Grand Tech Arena located at 4521 Innovation Drive\",\n",
    "  \"budget\": 50000,\n",
    "  \"deadline\": \"2024-02-20\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using Watsonx and Pydantic\n",
    "\n",
    "This tutorial showcases how to implement text classification tasks—specifically, single-label and multi-label classifications—using the Watsonx API and Pydantic models. If you want to see full examples check out the hub examples for single classification and multi classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Label Classification\n",
    "### Defining the Structures\n",
    "\n",
    "For single-label classification, we define a Pydantic model with a Literal field for the possible labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class ClassificationResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    A few-shot example of text classification:\n",
    "\n",
    "    Examples:\n",
    "    - \"Buy cheap watches now!\": SPAM\n",
    "    - \"Meeting at 3 PM in the conference room\": NOT_SPAM\n",
    "    - \"You've won a free iPhone! Click here\": SPAM\n",
    "    - \"Can you pick up some milk on your way home?\": NOT_SPAM\n",
    "    - \"Increase your followers by 10000 overnight!\": SPAM\n",
    "    \"\"\"\n",
    "\n",
    "    chain_of_thought: str = Field(\n",
    "        ...,\n",
    "        description=\"The chain of thought that led to the prediction.\",\n",
    "    )\n",
    "    label: Literal[\"SPAM\", \"NOT_SPAM\"] = Field(\n",
    "        ...,\n",
    "        description=\"The predicted class label.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Text\n",
    "\n",
    "The function classify will perform the single-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data: str) -> ClassificationResponse:\n",
    "    \"\"\"Perform single-label classification on the input text.\"\"\"\n",
    "    return instructor_client.messages.create(\n",
    "        response_model=ClassificationResponse,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Classify the following text: <text>{data}</text>\",\n",
    "            },\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Evaluation\n",
    "\n",
    "Let's run examples to see if it correctly identifies spam and non-spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for text, label in [\n",
    "        (\"Hey Jason! You're awesome\", \"NOT_SPAM\"),\n",
    "        (\"I am a nigerian prince and I need your help.\", \"SPAM\"),\n",
    "    ]:\n",
    "        prediction = classify(text)\n",
    "        assert prediction.label == label\n",
    "        print(f\"Text: {text}, Predicted Label: {prediction.label}\")\n",
    "        #> Text: Hey Jason! You're awesome, Predicted Label: NOT_SPAM\n",
    "        #> Text: I am a nigerian prince and I need your help., Predicted Label: SPAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Label Classification\n",
    "### Defining the Structures\n",
    "\n",
    "For multi-label classification, we'll update our approach to use Literals instead of enums, and include few-shot examples in the model's docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class MultiClassPrediction(BaseModel):\n",
    "    \"\"\"\n",
    "    Class for a multi-class label prediction.\n",
    "\n",
    "    Examples:\n",
    "    - \"My account is locked\": [\"TECH_ISSUE\"]\n",
    "    - \"I can't access my billing info\": [\"TECH_ISSUE\", \"BILLING\"]\n",
    "    - \"When do you close for holidays?\": [\"GENERAL_QUERY\"]\n",
    "    - \"My payment didn't go through and now I can't log in\": [\"BILLING\", \"TECH_ISSUE\"]\n",
    "    \"\"\"\n",
    "\n",
    "    chain_of_thought: str = Field(\n",
    "        ...,\n",
    "        description=\"The chain of thought that led to the prediction.\",\n",
    "    )\n",
    "\n",
    "    class_labels: List[Literal[\"TECH_ISSUE\", \"BILLING\", \"GENERAL_QUERY\"]] = Field(\n",
    "        ...,\n",
    "        description=\"The predicted class labels for the support ticket.\",\n",
    "    )\n",
    "class MultiClassPrediction(BaseModel):\n",
    "    \"\"\"\n",
    "    Class for a multi-class label prediction.\n",
    "\n",
    "    Examples:\n",
    "    - \"My account is locked\": [\"TECH_ISSUE\"]\n",
    "    - \"I can't access my billing info\": [\"TECH_ISSUE\", \"BILLING\"]\n",
    "    - \"When do you close for holidays?\": [\"GENERAL_QUERY\"]\n",
    "    - \"My payment didn't go through and now I can't log in\": [\"BILLING\", \"TECH_ISSUE\"]\n",
    "    \"\"\"\n",
    "\n",
    "    chain_of_thought: str = Field(\n",
    "        ...,\n",
    "        description=\"The chain of thought that led to the prediction.\",\n",
    "    )\n",
    "\n",
    "    class_labels: List[Literal[\"TECH_ISSUE\", \"BILLING\", \"GENERAL_QUERY\"]] = Field(\n",
    "        ...,\n",
    "        description=\"The predicted class labels for the support ticket.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Text\n",
    "\n",
    "The function multi_classify is responsible for multi-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_classify(data: str) -> MultiClassPrediction:\n",
    "    \"\"\"Perform multi-label classification on the input text.\"\"\"\n",
    "    return instructor_client.messages.create(\n",
    "        response_model=MultiClassPrediction,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Classify the following support ticket: <ticket>{data}</ticket>\",\n",
    "            },\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Evaluation\n",
    "\n",
    "Finally, we test the multi-label classification function using a sample support ticket.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multi-label classification\n",
    "ticket = \"My account is locked and I can't access my billing info.\"\n",
    "prediction = multi_classify(ticket)\n",
    "assert \"TECH_ISSUE\" in prediction.class_labels\n",
    "assert \"BILLING\" in prediction.class_labels\n",
    "print(f\"Ticket: {ticket}\")\n",
    "#> Ticket: My account is locked and I can't access my billing info.\n",
    "print(f\"Predicted Labels: {prediction.class_labels}\")\n",
    "#> Predicted Labels: ['TECH_ISSUE', 'BILLING']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Literals and including few-shot examples, we've improved both the single-label and multi-label classification implementations. These changes enhance type safety and provide better guidance for the AI model, potentially leading to more accurate classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answering Questions with Validated Citations\n",
    "\n",
    "For the full code example, check out examples/citation_fuzzy_match.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This example shows how to use Instructor with validators to not only add citations to answers generated but also prevent hallucinations by ensuring that every statement made by the LLM is backed up by a direct quote from the context provided, and that those quotes exist!\n",
    "Two Python classes, Fact and QuestionAnswer, are defined to encapsulate the information of individual facts and the entire answer, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures\n",
    "### The Fact Class\n",
    "\n",
    "The Fact class encapsulates a single statement or fact. It contains two fields:\n",
    "\n",
    "    fact: A string representing the body of the fact or statement.\n",
    "    substring_quote: A list of strings. Each string is a direct quote from the context that supports the fact.\n",
    "\n",
    "#### Validation Method: validate_sources\n",
    "\n",
    "This method validates the sources (substring_quote) in the context. It utilizes regex to find the span of each substring quote in the given context. If the span is not found, the quote is removed from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field, BaseModel, model_validator, ValidationInfo\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "class Fact(BaseModel):\n",
    "    fact: str = Field(...)\n",
    "    substring_quote: List[str] = Field(...)\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_sources(self, info: ValidationInfo) -> \"Fact\":\n",
    "        text_chunks = info.context.get(\"text_chunk\", None)\n",
    "        spans = list(self.get_spans(text_chunks))\n",
    "        self.substring_quote = [text_chunks[span[0] : span[1]] for span in spans]\n",
    "        return self\n",
    "\n",
    "    def get_spans(self, context):\n",
    "        for quote in self.substring_quote:\n",
    "            yield from self._get_span(quote, context)\n",
    "\n",
    "    def _get_span(self, quote, context):\n",
    "        for match in re.finditer(re.escape(quote), context):\n",
    "            yield match.span()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The QuestionAnswer Class¶\n",
    "\n",
    "This class encapsulates the question and its corresponding answer. It contains two fields:\n",
    "\n",
    "    question: The question asked.\n",
    "    answer: A list of Fact objects that make up the answer.\n",
    "\n",
    "#### Validation Method: validate_sources\n",
    "\n",
    "This method checks that each Fact object in the answer list has at least one valid source. If a Fact object has no valid sources, it is removed from the answer list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, model_validator\n",
    "from typing import List\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str = Field(...)\n",
    "    answer: List[Fact] = Field(...)\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_sources(self) -> \"QuestionAnswer\":\n",
    "        self.answer = [fact for fact in self.answer if len(fact.substring_quote) > 0]\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Ask AI a Question¶\n",
    "## The ask_ai Function\n",
    "\n",
    "This function takes a string question and a string context and returns a QuestionAnswer object. It uses the Watsonx API to fetch the answer and then validates the sources using the defined classes.\n",
    "\n",
    "To understand the validation context work from pydantic check out pydantic's docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tool_choice_option=\"auto\",\n",
    "def ask_ai(question: str, context: str) -> QuestionAnswer:\n",
    "    \n",
    "    return instructor_client.messages.create(\n",
    "        response_model=QuestionAnswer,\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'system', \n",
    "                'content': 'You are a world class assistant to answer questions with correct and exact citations based on a given CONTEXT.'\n",
    "            }, \n",
    "            {\n",
    "                'role': 'user', \n",
    "                'content': 'You are a world class assistant to answer questions with correct and exact citations based on a given CONTEXT.'\n",
    "            }, \n",
    "            {\n",
    "                'role': 'assistant', \n",
    "                'content': 'I have the following context uppon I have to base my answers.\\n' + f\"CONTEXT:{context}\\n\" \n",
    "            }, \n",
    "            {\n",
    "                'role': 'user', \n",
    "                'content': 'Question: ' + f'{question}'\n",
    "            }\n",
    "            \n",
    "            \n",
    "        ],\n",
    "        validation_context={\"text_chunk\": context},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import instructor\n",
    "\n",
    "# Apply the patch to the OpenAI client\n",
    "# enables response_model, validation_context keyword\n",
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "\n",
    "def ask_openai(question: str, context: str) -> QuestionAnswer:\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        response_model=QuestionAnswer,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a world class algorithm to answer questions with correct and exact citations.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f\"{context}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\"},\n",
    "        ],\n",
    "        validation_context={\"text_chunk\": context},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Here's an example of using these classes and functions to ask a question and validate the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did the author do during college?\"\n",
    "context = \"\"\"My name is Jason Liu, and I grew up in Toronto Canada but I was born in China. I went to an arts high school but in university I studied Computational Mathematics and physics. As part of coop I worked at many companies including Stitchfix, Facebook. I also started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging to DEBUG\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "print(ask_ai(question=question,context=context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging to DEBUG\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "ask_openai(question=question,context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Resolution and Visualization for Legal Documents\n",
    "\n",
    "In this guide, we demonstrate how to extract and resolve entities from a sample legal contract. Then, we visualize these entities and their dependencies as an entity graph. This approach can be invaluable for legal tech applications, aiding in the understanding of complex documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Data Structures\n",
    "\n",
    "The Entity and Property classes model extracted entities and their attributes. DocumentExtraction encapsulates a list of these entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Property(BaseModel):\n",
    "    key: str\n",
    "    value: str\n",
    "    resolved_absolute_value: str\n",
    "\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    id: int = Field(\n",
    "        ...,\n",
    "        description=\"Unique identifier for the entity, used for deduplication, design a scheme allows multiple entities\",\n",
    "    )\n",
    "    subquote_string: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"Correctly resolved value of the entity, if the entity is a reference to another entity, this should be the id of the referenced entity, include a few more words before and after the value to allow for some context to be used in the resolution\",\n",
    "    )\n",
    "    entity_title: str\n",
    "    properties: List[Property] = Field(\n",
    "        ..., description=\"List of properties of the entity\"\n",
    "    )\n",
    "    dependencies: List[int] = Field(\n",
    "        ...,\n",
    "        description=\"List of entity ids that this entity depends  or relies on to resolve it\",\n",
    "    )\n",
    "\n",
    "\n",
    "class DocumentExtraction(BaseModel):\n",
    "    entities: List[Entity] = Field(\n",
    "        ...,\n",
    "        description=\"Body of the answer, each fact should be a separate object with a body and a list of sources\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Extraction and Resolution\n",
    "\n",
    "The ask_ai function utilizes Watsonx API to extract and resolve entities from the input content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "# Apply the patch to the OpenAI client\n",
    "# enables response_model keyword\n",
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "\n",
    "def ask_ai(content) -> DocumentExtraction:\n",
    "    return instructor_client.messages.create(\n",
    "        #tool_choice_option=\"auto\",\n",
    "        response_model=DocumentExtraction,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Extract and resolve a list of entities from the following document:\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content,\n",
    "            },\n",
    "        ],\n",
    "    )  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Visualization\n",
    "\n",
    "generate_graph takes the extracted entities and visualizes them using Graphviz. It creates nodes for each entity and edges for their dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def generate_html_label(entity: Entity) -> str:\n",
    "    rows = [\n",
    "        f\"<tr><td>{prop.key}</td><td>{prop.resolved_absolute_value}</td></tr>\"\n",
    "        for prop in entity.properties\n",
    "    ]\n",
    "    table_rows = \"\".join(rows)\n",
    "    return f\"<<table border='0' cellborder='1' cellspacing='0'><tr><td colspan='2'><b>{entity.entity_title}</b></td></tr>{table_rows}</table>>\"\n",
    "\n",
    "\n",
    "def generate_graph(data: DocumentExtraction):\n",
    "    dot = Digraph(comment=\"Entity Graph\", node_attr={\"shape\": \"plaintext\"})\n",
    "\n",
    "    for entity in data.entities:\n",
    "        label = generate_html_label(entity)\n",
    "        dot.node(str(entity.id), label)\n",
    "\n",
    "    for entity in data.entities:\n",
    "        for dep_id in entity.dependencies:\n",
    "            dot.edge(str(entity.id), str(dep_id))\n",
    "\n",
    "    dot.render(\"entity.gv\", view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "\n",
    "Finally, execute the code to visualize the entity graph for the sample legal contract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "Sample Legal Contract\n",
    "Agreement Contract\n",
    "\n",
    "This Agreement is made and entered into on 2020-01-01 by and between Company A (\"the Client\") and Company B (\"the Service Provider\").\n",
    "\n",
    "Article 1: Scope of Work\n",
    "\n",
    "The Service Provider will deliver the software product to the Client 30 days after the agreement date.\n",
    "\n",
    "Article 2: Payment Terms\n",
    "\n",
    "The total payment for the service is $50,000.\n",
    "An initial payment of $10,000 will be made within 7 days of the the signed date.\n",
    "The final payment will be due 45 days after [SignDate].\n",
    "\n",
    "Article 3: Confidentiality\n",
    "\n",
    "The parties agree not to disclose any confidential information received from the other party for 3 months after the final payment date.\n",
    "\n",
    "Article 4: Termination\n",
    "\n",
    "The contract can be terminated with a 30-day notice, unless there are outstanding obligations that must be fulfilled after the [DeliveryDate].\n",
    "\"\"\"  # Your legal contract here\n",
    "model = ask_ai(content)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PII Data Extraction and Scrubbing\n",
    "## Overview\n",
    "\n",
    "This example demonstrates the usage of OpenAI's ChatCompletion model for the extraction and scrubbing of Personally Identifiable Information (PII) from a document. The code defines Pydantic models to manage the PII data and offers methods for both extraction and sanitation.\n",
    "\n",
    "## Defining the Structures\n",
    "\n",
    "First, Pydantic models are defined to represent the PII data and the overall structure for PII data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# Define Schemas for PII data\n",
    "class Data(BaseModel):\n",
    "    index: int\n",
    "    data_type: str\n",
    "    pii_value: str\n",
    "\n",
    "\n",
    "class PIIDataExtraction(BaseModel):\n",
    "    \"\"\"\n",
    "    Extracted PII data from a document, all data_types should try to have consistent property names\n",
    "    \"\"\"\n",
    "\n",
    "    private_data: List[Data]\n",
    "\n",
    "    def scrub_data(self, content: str) -> str:\n",
    "        \"\"\"\n",
    "        Iterates over the private data and replaces the value with a placeholder in the form of\n",
    "        <{data_type}_{i}>\n",
    "        \"\"\"\n",
    "        for i, data in enumerate(self.private_data):\n",
    "            content = content.replace(data.pii_value, f\"<{data.data_type}_{i}>\")\n",
    "        return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting PII Data\n",
    "\n",
    "The OpenAI API is utilized to extract PII information from a given document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_DOCUMENT = \"\"\"\n",
    "# Fake Document with PII for Testing PII Scrubbing Model\n",
    "# (The content here)\n",
    "\"\"\"\n",
    "\n",
    "pii_data = instructor_client.messages.create(\n",
    "    response_model=PIIDataExtraction,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a world class PII scrubbing model, Extract the PII data from the following document\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": EXAMPLE_DOCUMENT,\n",
    "        },\n",
    "    ],\n",
    ")  # type: ignore\n",
    "\n",
    "print(\"Extracted PII Data:\")\n",
    "#> Extracted PII Data:\n",
    "print(pii_data.model_dump_json())\n",
    "\"\"\"\n",
    "{\"private_data\":[{\"index\":0,\"data_type\":\"Name\",\"pii_value\":\"John Doe\"},{\"index\":1,\"data_type\":\"Email\",\"pii_value\":\"john.doe@example.com\"},{\"index\":2,\"data_type\":\"Phone Number\",\"pii_value\":\"(555) 123-4567\"},{\"index\":3,\"data_type\":\"Address\",\"pii_value\":\"123 Main St, Anytown, USA\"},{\"index\":4,\"data_type\":\"Social Security Number\",\"pii_value\":\"123-45-6789\"}]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrubbing PII Data\n",
    "\n",
    "After extracting the PII data, the scrub_data method is used to sanitize the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scrubbed Document:\")\n",
    "#> Scrubbed Document:\n",
    "print(pii_data.scrub_data(EXAMPLE_DOCUMENT))\n",
    "\"\"\"\n",
    "# Fake Document with PII for Testing PII Scrubbing Model\n",
    "# He was born on <date_0>. His social security number is <ssn_1>. He has been using the email address <email_2> for years, and he can always be reached at <phone_3>.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Tables using Watsonx.ai\n",
    "\n",
    "This post demonstrates how to use Python's type annotations and Watsonx new vision model to extract tables from images and convert them into markdown format. This method is particularly useful for data analysis and automation tasks.\n",
    "\n",
    "The full code is available on GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Custom Type for Markdown Tables\n",
    "\n",
    "First, we define a custom type, MarkdownDataFrame, to handle pandas DataFrames formatted in markdown. This type uses Python's Annotated and InstanceOf types, along with decorators BeforeValidator and PlainSerializer, to process and serialize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from typing import Annotated, Any\n",
    "from pydantic import BeforeValidator, PlainSerializer, InstanceOf, WithJsonSchema\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def md_to_df(data: Any) -> Any:\n",
    "    # Convert markdown to DataFrame\n",
    "    if isinstance(data, str):\n",
    "        return (\n",
    "            pd.read_csv(\n",
    "                StringIO(data),  # Process data\n",
    "                sep=\"|\",\n",
    "                index_col=1,\n",
    "            )\n",
    "            .dropna(axis=1, how=\"all\")\n",
    "            .iloc[1:]\n",
    "            .applymap(lambda x: x.strip())\n",
    "        )\n",
    "    return data\n",
    "\n",
    "\n",
    "MarkdownDataFrame = Annotated[\n",
    "    InstanceOf[pd.DataFrame],\n",
    "    BeforeValidator(md_to_df),\n",
    "    PlainSerializer(lambda df: df.to_markdown()),\n",
    "    WithJsonSchema(\n",
    "        {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The markdown representation of the table, each one should be tidy, do not try to join tables that should be seperate\",\n",
    "        }\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Table Class¶\n",
    "\n",
    "The Table class is essential for organizing the extracted data. It includes a caption and a dataframe, processed as a markdown table. Since most of the complexity is handled by the MarkdownDataFrame type, the Table class is straightforward!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Table(BaseModel):\n",
    "    caption: str\n",
    "    dataframe: MarkdownDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Tables from Images\n",
    "\n",
    "The extract_table function uses Watsonx vision model to process an image URL and extract tables in markdown format. We utilize the instructor library to patch the OpenAI client for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from typing import Iterable\n",
    "import base64\n",
    "import requests\n",
    "from ibm_watsonx_ai.foundation_models.schema import TextChatParameters\n",
    "\n",
    "# Apply the patch to the client to support response_model\n",
    "# Also use MD_JSON mode since the vision model does not support any special structured output mode\n",
    "\n",
    "params = TextChatParameters(\n",
    "    temperature=1,\n",
    "    max_tokens=2000,\n",
    "    time_limit=600000\n",
    ")\n",
    "\n",
    "client = Model(\n",
    "    model_id='meta-llama/llama-3-2-90b-vision-instruct',\n",
    "    params=params,\n",
    "    credentials=Credentials(\n",
    "        api_key = os.environ.get(\"WATSONX_API_KEY\"),\n",
    "        url = os.environ.get(\"WATSONX_URL\")),\n",
    "    project_id= os.environ.get(\"WATSONX_PROJECT_ID\")\n",
    ")\n",
    "\n",
    "# Patch the client with Watsonx\n",
    "instructor_client=instructor.from_watsonx(\n",
    "    client=client,\n",
    "    mode=instructor.Mode.WATSONX_MD_JSON #WATSONX_TOOLS #instructor.function_calls.Mode.MD_JSON\n",
    ")\n",
    "\n",
    "\n",
    "def extract_table(url: str) -> Iterable[Table]:\n",
    "    url = url\n",
    "    response = requests.get(url)\n",
    "    encoded_string = base64.b64encode(response.content).decode('utf-8')\n",
    "\n",
    "    return instructor_client.messages.create(\n",
    "        response_model=Iterable[Table],\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Extract table from image.\"},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                        \"url\": \"data:image/jpeg;base64,\" + encoded_string,\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "\n",
    "url=\"https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png\"\n",
    "response = requests.get(url)\n",
    "encoded_string = base64.b64encode(response.content).decode('utf-8')\n",
    "question = \"Describe photo content\"\n",
    "\n",
    "params = TextChatParameters(\n",
    "    temperature=1,\n",
    "    max_tokens=2000,\n",
    "    time_limit=600000\n",
    ")\n",
    "\n",
    "client = Model(\n",
    "    model_id='meta-llama/llama-3-2-90b-vision-instruct',#'meta-llama/llama-3-70b-instruct',\n",
    "    params=params,\n",
    "    credentials=Credentials(\n",
    "        api_key = os.environ.get(\"WATSONX_API_KEY\"),\n",
    "        url = os.environ.get(\"WATSONX_URL\")),\n",
    "    project_id= os.environ.get(\"WATSONX_PROJECT_ID\")\n",
    ")\n",
    "\n",
    "\n",
    "messages = [\n",
    "  {\n",
    "    'role': 'user', \n",
    "    'content': 'As a genius expert, your task is to understand the content and provide the parsed objects in json that match the following json_schema:\\n\\n\\n        {\\n  \"$defs\": {\\n    \"Table\": {\\n      \"properties\": {\\n        \"caption\": {\\n          \"title\": \"Caption\",\\n          \"type\": \"string\"\\n        },\\n        \"dataframe\": {\\n          \"description\": \"The markdown representation of the table, each one should be tidy, do not try to join tables that should be seperate\",\\n          \"title\": \"Dataframe\",\\n          \"type\": \"string\"\\n        }\\n      },\\n      \"required\": [\\n        \"caption\",\\n        \"dataframe\"\\n      ],\\n      \"title\": \"Table\",\\n      \"type\": \"object\"\\n    }\\n  },\\n  \"description\": \"Correct segmentation of `Table` tasks\",\\n  \"properties\": {\\n    \"tasks\": {\\n      \"description\": \"Correctly segmented list of `Table` tasks\",\\n      \"items\": {\\n        \"$ref\": \"#/$defs/Table\"\\n      },\\n      \"title\": \"Tasks\",\\n      \"type\": \"array\"\\n    }\\n  },\\n  \"title\": \"IterableTable\",\\n  \"type\": \"object\"\\n}\\n\\n        Make sure to return an instance of the JSON, not the schema itself\\n'\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": question\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "          \"url\": \"data:image/jpeg;base64,\" + encoded_string,\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        'type': 'text',\n",
    "        'text': 'Return the correct JSON response within a ```json codeblock. not the JSON_SCHEMA'\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "response = client.chat(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from typing import Iterable\n",
    "\n",
    "\n",
    "# Apply the patch to the OpenAI client to support response_model\n",
    "# Also use MD_JSON mode since the visino model does not support any special structured output mode\n",
    "client = instructor.from_openai(OpenAI(), mode=instructor.function_calls.Mode.MD_JSON)\n",
    "\n",
    "#max_tokens=1800,\n",
    "def extract_table(url: str) -> Iterable[Table]:\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        response_model=Iterable[Table],\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Extract table from image.\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": url}},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Example\n",
    "\n",
    "In this example, we apply the method to extract data from an image showing the top grossing apps in Ireland for October 2023.\n",
    "\n",
    "<img src=\"https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png\"\n",
    "#url=\"https://i.postimg.cc/0NSPJpyF/Screenshot-2024-10-29-at-5-30-55-PM.png\"\n",
    "# Set logging to DEBUG\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "tables = extract_table(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatCompletion(id='chatcmpl-ANq9zKHKiyG3EraDghRHnvwUriXwk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n{\\n  \"tasks\": [\\n    {\\n      \"caption\": \"Top 10 grossing apps on Android in October 2023 (Ireland)\",\\n      \"dataframe\": \"| Rank | App Name                          | Category            |\\\\n|------|-----------------------------------|---------------------|\\\\n| 1    | Google One                       | Productivity        |\\\\n| 2    | Disney+                          | Entertainment       |\\\\n| 3    | TikTok - Videos, Music & LIVE   | Entertainment       |\\\\n| 4    | Candy Crush Saga                 | Games               |\\\\n| 5    | Tinder: Dating, Chat & Friends   | Social networking    |\\\\n| 6    | Coin Master                      | Games               |\\\\n| 7    | Roblox                           | Games               |\\\\n| 8    | Bumble - Dating & Make Friends   | Dating              |\\\\n| 9    | Royal Match                      | Games               |\\\\n| 10   | Spotify: Music and Podcasts      | Music & Audio       |\"\\n    },\\n    {\\n      \"caption\": \"Top 10 grossing apps on iOS in October 2023 (Ireland)\",\\n      \"dataframe\": \"| Rank | App Name                          | Category            |\\\\n|------|-----------------------------------|---------------------|\\\\n| 1    | Tinder: Dating, Chat & Friends    | Social networking    |\\\\n| 2    | Disney+                          | Entertainment       |\\\\n| 3    | YouTube: Watch, Listen, Stream   | Entertainment       |\\\\n| 4    | Audible: Audio Entertainment      | Entertainment       |\\\\n| 5    | Candy Crush Saga                 | Games               |\\\\n| 6    | TikTok - Videos, Music & LIVE    | Entertainment       |\\\\n| 7    | Bumble - Dating & Make Friends    | Dating              |\\\\n| 8    | Roblox                           | Games               |\\\\n| 9    | LinkedIn: Job Search & News      | Business            |\\\\n| 10   | Duolingo - Language Lessons      | Education           |\"\\n    }\\n  ]\\n}\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1730245411, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_8bfc6a7dc2', usage=CompletionUsage(completion_tokens=430, prompt_tokens=25792, total_tokens=26222, completion_tokens_details=None, prompt_tokens_details=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in tables:\n",
    "\n",
    "    print(table.dataframe)\n",
    "    \"\"\"\n",
    "           Android                                      ... Category\n",
    "     Rank                                               ...\n",
    "    1                                       Google One  ...      Social networking\n",
    "    2                                          Disney+  ...          Entertainment\n",
    "    3                    TikTok - Videos, Music & LIVE  ...          Entertainment\n",
    "    4                                 Candy Crush Saga  ...          Entertainment\n",
    "    5                   Tinder: Dating, Chat & Friends  ...                  Games\n",
    "    6                                      Coin Master  ...          Entertainment\n",
    "    7                                           Roblox  ...                 Dating\n",
    "    8                   Bumble - Dating & Make Friends  ...                  Games\n",
    "    9                                      Royal Match  ...               Business\n",
    "    10                     Spotify: Music and Podcasts  ...              Education\n",
    "\n",
    "    [10 rows x 4 columns]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion={'id': 'chat-2efdc8348d694a51b023cc51a87a24cc', 'model_id': 'meta-llama/llama-3-2-90b-vision-instruct', 'model': 'meta-llama/llama-3-2-90b-vision-instruct', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'The table in the image displays the top 10 grossing apps in October 2023 for both Android and iOS devices in Ireland. The table is divided into two columns, with the left column showing the top 10 grossing Android apps and the right column showing the top 10 grossing iOS apps.\\n\\nTo extract the table from the image and return the correct JSON response within a ```json codeblock, we can follow these steps:\\n\\n1. Identify the table structure: The table has two columns, with the left column showing the top 10 grossing Android apps and the right column showing the top 10 grossing iOS apps.\\n2. Extract the data: We can extract the data from the table by reading the text in each cell.\\n3. Create the JSON response: We can create the JSON response by using the extracted data to populate the \"tasks\" array.\\n\\nHere is the extracted table in JSON format:\\n\\n```json\\n{\\n  \"tasks\": [\\n    {\\n      \"caption\": \"Top 10 grossing apps in October 2023 (Ireland)\",\\n      \"dataframe\": \"Google One 1 Tinder: Dating, Chat & Friends 1\\\\nDisney+ 2 Disney+ 2\\\\nTikTok - Videos, Music & LIVE 3 YouTube: Watch, Listen, Stream 3\\\\nCandy Crush Saga 4 Audible: Audio Entertainment 4\\\\nTinder: Dating, Chat & Friends 5 Candy Crush Saga 5\\\\nCoin Master 6 TikTok - Videos, Music & LIVE 6\\\\nRoblox 7 Bumble - Dating & Make Friends 7\\\\nBumble - Dating & Make Friends 8 Roblox 8\\\\nRoyal Match 9 LinkedIn: Job Search & News 9\\\\nSpotify: Music and Podcasts 10 Duolingo - Language Lessons 10\"\\n    }\\n  ]\\n}\\n```\\n\\nThis JSON response includes a single \"task\" object with a \"caption\" property containing the title of the table and a \"dataframe\" property containing the markdown representation of the table. The \"dataframe\" property is a string that represents the table in a tidy format, with each row separated by a newline character and each column separated by a space.'}, 'finish_reason': 'stop'}], 'created': 1730245465, 'model_version': '3.2.0', 'created_at': '2024-10-29T23:44:41.056Z', 'usage': {'completion_tokens': 449, 'prompt_tokens': 6700, 'total_tokens': 7149}, 'system': {'warnings': [{'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.', 'id': 'disclaimer_warning', 'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'}, {'message': \"The value of 'max_tokens' for this model was set to value 1024\", 'id': 'unspecified_max_token', 'additional_properties': {'limit': 0, 'new_value': 1024, 'parameter': 'max_tokens', 'value': 0}}]}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat import ChatCompletion\n",
    "\n",
    "completion[\"model\"]=completion[\"model_id\"]\n",
    "completion[\"object\"]=\"chat.completion\" \n",
    "completion[\"text\"]=\"\" \n",
    "completion= ChatCompletion(**completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
