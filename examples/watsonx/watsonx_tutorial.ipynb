{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append( '/Users/andreswagner/Documents/GitHub/instructor' )\n",
    "module_path = os.path.abspath(os.path.join('/Users/andreswagner/Documents/GitHub/instructor'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started in Minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Instructor with a single command:\n",
    "\n",
    "```bash\n",
    "pip install -U instructor\n",
    "pip install ibm-watsonx-ai\n",
    "```\n",
    "\n",
    "Now, let's see Instructor in action with a simple example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import instructor\n",
    "import logging\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired output structure\n",
    "class UserInfo(BaseModel):\n",
    "    name: str\n",
    "    age: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "\n",
    "\n",
    "#from instructor import from_watsonx\n",
    "from instructor.function_calls import Mode\n",
    "\n",
    "\n",
    "client = Model(\n",
    "    model_id='mistralai/mistral-large',#'meta-llama/llama-3-70b-instruct',\n",
    "    params={\"tool_choice\":'auto'},\n",
    "    credentials=Credentials(\n",
    "        api_key = os.environ.get(\"WATSONX_API_KEY\"),\n",
    "        url = os.environ.get(\"WATSONX_URL\")),\n",
    "    project_id= os.environ.get(\"WATSONX_PROJECT_ID\")\n",
    ")\n",
    "\n",
    "# Patch the client with Watsonx\n",
    "instructor_client=instructor.from_watsonx(\n",
    "    client=client,\n",
    "    mode=instructor.Mode.WATSONX_TOOLS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreswagner/Documents/GitHub/instructor/.venv/lib/python3.12/site-packages/ibm_watsonx_ai/foundation_models/inference/base_model_inference.py:723: UserWarning: Parameters [tool_choice] is/are not recognized and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='John Doe' age=30\n"
     ]
    }
   ],
   "source": [
    "# Set logging to DEBUG\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "user_info = instructor_client.messages.create(\n",
    "    response_model=UserInfo,\n",
    "    max_retries=3,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"John Doe is 30 years old.\"}],\n",
    ")\n",
    "print(user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(user_info.name)\n",
    "print(user_info.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Hooks\n",
    "Instructor provides a powerful hooks system that allows you to intercept and log various stages of the LLM interaction process. Here's a simple example demonstrating how to use hooks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function called with kwargs: {'messages': [{'role': 'user', 'content': \"Extract the user name: 'John is 20 years old'\"}], 'tools': [{'type': 'function', 'function': {'name': 'UserInfo', 'description': 'Correctly extracted `UserInfo` with all the required parameters with correct types', 'parameters': {'properties': {'name': {'title': 'Name', 'type': 'string'}, 'age': {'title': 'Age', 'type': 'integer'}}, 'required': ['age', 'name'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'UserInfo'}}}\n"
     ]
    }
   ],
   "source": [
    "# Define hook functions\n",
    "def log_kwargs(**kwargs):\n",
    "    print(f\"Function called with kwargs: {kwargs}\")\n",
    "\n",
    "def log_exception(exception: Exception):\n",
    "    print(f\"An exception occurred: {str(exception)}\")\n",
    "\n",
    "instructor_client.on(\"completion:kwargs\", log_kwargs)\n",
    "instructor_client.on(\"completion:error\", log_exception)\n",
    "\n",
    "user_info = instructor_client.messages.create(\n",
    "    \n",
    "    response_model=UserInfo,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Extract the user name: 'John is 20 years old'\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: John, Age: 20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name: {user_info.name}, Age: {user_info.age}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using Watsonx and Pydantic\n",
    "\n",
    "This tutorial showcases how to implement text classification tasks—specifically, single-label and multi-label classifications—using the Watsonx API and Pydantic models. If you want to see full examples check out the hub examples for single classification and multi classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Label Classification\n",
    "### Defining the Structures\n",
    "\n",
    "For single-label classification, we define a Pydantic model with a Literal field for the possible labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class ClassificationResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    A few-shot example of text classification:\n",
    "\n",
    "    Examples:\n",
    "    - \"Buy cheap watches now!\": SPAM\n",
    "    - \"Meeting at 3 PM in the conference room\": NOT_SPAM\n",
    "    - \"You've won a free iPhone! Click here\": SPAM\n",
    "    - \"Can you pick up some milk on your way home?\": NOT_SPAM\n",
    "    - \"Increase your followers by 10000 overnight!\": SPAM\n",
    "    \"\"\"\n",
    "\n",
    "    chain_of_thought: str = Field(\n",
    "        ...,\n",
    "        description=\"The chain of thought that led to the prediction.\",\n",
    "    )\n",
    "    label: Literal[\"SPAM\", \"NOT_SPAM\"] = Field(\n",
    "        ...,\n",
    "        description=\"The predicted class label.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Text\n",
    "\n",
    "The function classify will perform the single-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data: str) -> ClassificationResponse:\n",
    "    \"\"\"Perform single-label classification on the input text.\"\"\"\n",
    "    return instructor_client.messages.create(\n",
    "        response_model=ClassificationResponse,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Classify the following text: <text>{data}</text>\",\n",
    "            },\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Evaluation\n",
    "\n",
    "Let's run examples to see if it correctly identifies spam and non-spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Hey Jason! You're awesome, Predicted Label: NOT_SPAM\n",
      "Text: I am a nigerian prince and I need your help., Predicted Label: SPAM\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for text, label in [\n",
    "        (\"Hey Jason! You're awesome\", \"NOT_SPAM\"),\n",
    "        (\"I am a nigerian prince and I need your help.\", \"SPAM\"),\n",
    "    ]:\n",
    "        prediction = classify(text)\n",
    "        assert prediction.label == label\n",
    "        print(f\"Text: {text}, Predicted Label: {prediction.label}\")\n",
    "        #> Text: Hey Jason! You're awesome, Predicted Label: NOT_SPAM\n",
    "        #> Text: I am a nigerian prince and I need your help., Predicted Label: SPAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Label Classification\n",
    "### Defining the Structures\n",
    "\n",
    "For multi-label classification, we'll update our approach to use Literals instead of enums, and include few-shot examples in the model's docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class MultiClassPrediction(BaseModel):\n",
    "    \"\"\"\n",
    "    Class for a multi-class label prediction.\n",
    "\n",
    "    Examples:\n",
    "    - \"My account is locked\": [\"TECH_ISSUE\"]\n",
    "    - \"I can't access my billing info\": [\"TECH_ISSUE\", \"BILLING\"]\n",
    "    - \"When do you close for holidays?\": [\"GENERAL_QUERY\"]\n",
    "    - \"My payment didn't go through and now I can't log in\": [\"BILLING\", \"TECH_ISSUE\"]\n",
    "    \"\"\"\n",
    "\n",
    "    chain_of_thought: str = Field(\n",
    "        ...,\n",
    "        description=\"The chain of thought that led to the prediction.\",\n",
    "    )\n",
    "\n",
    "    class_labels: List[Literal[\"TECH_ISSUE\", \"BILLING\", \"GENERAL_QUERY\"]] = Field(\n",
    "        ...,\n",
    "        description=\"The predicted class labels for the support ticket.\",\n",
    "    )\n",
    "class MultiClassPrediction(BaseModel):\n",
    "    \"\"\"\n",
    "    Class for a multi-class label prediction.\n",
    "\n",
    "    Examples:\n",
    "    - \"My account is locked\": [\"TECH_ISSUE\"]\n",
    "    - \"I can't access my billing info\": [\"TECH_ISSUE\", \"BILLING\"]\n",
    "    - \"When do you close for holidays?\": [\"GENERAL_QUERY\"]\n",
    "    - \"My payment didn't go through and now I can't log in\": [\"BILLING\", \"TECH_ISSUE\"]\n",
    "    \"\"\"\n",
    "\n",
    "    chain_of_thought: str = Field(\n",
    "        ...,\n",
    "        description=\"The chain of thought that led to the prediction.\",\n",
    "    )\n",
    "\n",
    "    class_labels: List[Literal[\"TECH_ISSUE\", \"BILLING\", \"GENERAL_QUERY\"]] = Field(\n",
    "        ...,\n",
    "        description=\"The predicted class labels for the support ticket.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Text\n",
    "\n",
    "The function multi_classify is responsible for multi-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_classify(data: str) -> MultiClassPrediction:\n",
    "    \"\"\"Perform multi-label classification on the input text.\"\"\"\n",
    "    return instructor_client.messages.create(\n",
    "        response_model=MultiClassPrediction,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Classify the following support ticket: <ticket>{data}</ticket>\",\n",
    "            },\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Evaluation\n",
    "\n",
    "Finally, we test the multi-label classification function using a sample support ticket.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket: My account is locked and I can't access my billing info.\n",
      "Predicted Labels: ['TECH_ISSUE', 'BILLING']\n"
     ]
    }
   ],
   "source": [
    "# Test multi-label classification\n",
    "ticket = \"My account is locked and I can't access my billing info.\"\n",
    "prediction = multi_classify(ticket)\n",
    "assert \"TECH_ISSUE\" in prediction.class_labels\n",
    "assert \"BILLING\" in prediction.class_labels\n",
    "print(f\"Ticket: {ticket}\")\n",
    "#> Ticket: My account is locked and I can't access my billing info.\n",
    "print(f\"Predicted Labels: {prediction.class_labels}\")\n",
    "#> Predicted Labels: ['TECH_ISSUE', 'BILLING']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Literals and including few-shot examples, we've improved both the single-label and multi-label classification implementations. These changes enhance type safety and provide better guidance for the AI model, potentially leading to more accurate classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answering Questions with Validated Citations\n",
    "\n",
    "For the full code example, check out examples/citation_fuzzy_match.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This example shows how to use Instructor with validators to not only add citations to answers generated but also prevent hallucinations by ensuring that every statement made by the LLM is backed up by a direct quote from the context provided, and that those quotes exist!\n",
    "Two Python classes, Fact and QuestionAnswer, are defined to encapsulate the information of individual facts and the entire answer, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures\n",
    "### The Fact Class\n",
    "\n",
    "The Fact class encapsulates a single statement or fact. It contains two fields:\n",
    "\n",
    "    fact: A string representing the body of the fact or statement.\n",
    "    substring_quote: A list of strings. Each string is a direct quote from the context that supports the fact.\n",
    "\n",
    "#### Validation Method: validate_sources\n",
    "\n",
    "This method validates the sources (substring_quote) in the context. It utilizes regex to find the span of each substring quote in the given context. If the span is not found, the quote is removed from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field, BaseModel, model_validator, ValidationInfo\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "class Fact(BaseModel):\n",
    "    fact: str = Field(...)\n",
    "    substring_quote: List[str] = Field(...)\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_sources(self, info: ValidationInfo) -> \"Fact\":\n",
    "        text_chunks = info.context.get(\"text_chunk\", None)\n",
    "        spans = list(self.get_spans(text_chunks))\n",
    "        self.substring_quote = [text_chunks[span[0] : span[1]] for span in spans]\n",
    "        return self\n",
    "\n",
    "    def get_spans(self, context):\n",
    "        for quote in self.substring_quote:\n",
    "            yield from self._get_span(quote, context)\n",
    "\n",
    "    def _get_span(self, quote, context):\n",
    "        for match in re.finditer(re.escape(quote), context):\n",
    "            yield match.span()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The QuestionAnswer Class¶\n",
    "\n",
    "This class encapsulates the question and its corresponding answer. It contains two fields:\n",
    "\n",
    "    question: The question asked.\n",
    "    answer: A list of Fact objects that make up the answer.\n",
    "\n",
    "#### Validation Method: validate_sources\n",
    "\n",
    "This method checks that each Fact object in the answer list has at least one valid source. If a Fact object has no valid sources, it is removed from the answer list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, model_validator\n",
    "from typing import List\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str = Field(...)\n",
    "    answer: List[Fact] = Field(...)\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_sources(self) -> \"QuestionAnswer\":\n",
    "        self.answer = [fact for fact in self.answer if len(fact.substring_quote) > 0]\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Ask AI a Question¶\n",
    "## The ask_ai Function\n",
    "\n",
    "This function takes a string question and a string context and returns a QuestionAnswer object. It uses the Watsonx API to fetch the answer and then validates the sources using the defined classes.\n",
    "\n",
    "To understand the validation context work from pydantic check out pydantic's docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tool_choice_option=\"auto\",\n",
    "def ask_ai(question: str, context: str) -> QuestionAnswer:\n",
    "    \n",
    "    return instructor_client.messages.create(\n",
    "        response_model=QuestionAnswer,\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'system', \n",
    "                'content': 'You are a world class assistant to answer questions with correct and exact citations based on a given CONTEXT.'\n",
    "            }, \n",
    "            {\n",
    "                'role': 'user', \n",
    "                'content': 'You are a world class assistant to answer questions with correct and exact citations based on a given CONTEXT.'\n",
    "            }, \n",
    "            {\n",
    "                'role': 'assistant', \n",
    "                'content': 'I have the following context uppon I have to base my answers.\\n' + f\"CONTEXT:{context}\\n\" \n",
    "            }, \n",
    "            {\n",
    "                'role': 'user', \n",
    "                'content': 'Question: ' + f'{question}'\n",
    "            }\n",
    "            \n",
    "            \n",
    "        ],\n",
    "        validation_context={\"text_chunk\": context},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Here's an example of using these classes and functions to ask a question and validate the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did the author do during college?\"\n",
    "context = \"\"\"My name is Jason Liu, and I grew up in Toronto Canada but I was born in China. I went to an arts high school but in university I studied Computational Mathematics and physics. As part of coop I worked at many companies including Stitchfix, Facebook. I also started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question='What did the author do during college?' answer=[Fact(fact='I started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.', substring_quote=['I was the president of the club for 2 years.'])]\n"
     ]
    }
   ],
   "source": [
    "# Set logging to DEBUG\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "print(ask_ai(question=question,context=context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Resolution and Visualization for Legal Documents\n",
    "\n",
    "In this guide, we demonstrate how to extract and resolve entities from a sample legal contract. Then, we visualize these entities and their dependencies as an entity graph. This approach can be invaluable for legal tech applications, aiding in the understanding of complex documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Data Structures\n",
    "\n",
    "The Entity and Property classes model extracted entities and their attributes. DocumentExtraction encapsulates a list of these entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Property(BaseModel):\n",
    "    key: str\n",
    "    value: str\n",
    "    resolved_absolute_value: str\n",
    "\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    id: int = Field(\n",
    "        ...,\n",
    "        description=\"Unique identifier for the entity, used for deduplication, design a scheme allows multiple entities\",\n",
    "    )\n",
    "    subquote_string: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"Correctly resolved value of the entity, if the entity is a reference to another entity, this should be the id of the referenced entity, include a few more words before and after the value to allow for some context to be used in the resolution\",\n",
    "    )\n",
    "    entity_title: str\n",
    "    properties: List[Property] = Field(\n",
    "        ..., description=\"List of properties of the entity\"\n",
    "    )\n",
    "    dependencies: List[int] = Field(\n",
    "        ...,\n",
    "        description=\"List of entity ids that this entity depends  or relies on to resolve it\",\n",
    "    )\n",
    "\n",
    "\n",
    "class DocumentExtraction(BaseModel):\n",
    "    entities: List[Entity] = Field(\n",
    "        ...,\n",
    "        description=\"Body of the answer, each fact should be a separate object with a body and a list of sources\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Extraction and Resolution\n",
    "\n",
    "The ask_ai function utilizes Watsonx API to extract and resolve entities from the input content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "# Apply the patch to the OpenAI client\n",
    "# enables response_model keyword\n",
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "\n",
    "def ask_ai(content) -> DocumentExtraction:\n",
    "    return instructor_client.messages.create(\n",
    "        #tool_choice_option=\"auto\",\n",
    "        response_model=DocumentExtraction,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Extract and resolve a list of entities from the following document:\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content,\n",
    "            },\n",
    "        ],\n",
    "    )  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Visualization\n",
    "\n",
    "generate_graph takes the extracted entities and visualizes them using Graphviz. It creates nodes for each entity and edges for their dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def generate_html_label(entity: Entity) -> str:\n",
    "    rows = [\n",
    "        f\"<tr><td>{prop.key}</td><td>{prop.resolved_absolute_value}</td></tr>\"\n",
    "        for prop in entity.properties\n",
    "    ]\n",
    "    table_rows = \"\".join(rows)\n",
    "    return f\"<<table border='0' cellborder='1' cellspacing='0'><tr><td colspan='2'><b>{entity.entity_title}</b></td></tr>{table_rows}</table>>\"\n",
    "\n",
    "\n",
    "def generate_graph(data: DocumentExtraction):\n",
    "    dot = Digraph(comment=\"Entity Graph\", node_attr={\"shape\": \"plaintext\"})\n",
    "\n",
    "    for entity in data.entities:\n",
    "        label = generate_html_label(entity)\n",
    "        dot.node(str(entity.id), label)\n",
    "\n",
    "    for entity in data.entities:\n",
    "        for dep_id in entity.dependencies:\n",
    "            dot.edge(str(entity.id), str(dep_id))\n",
    "\n",
    "    dot.render(\"entity.gv\", view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "\n",
    "Finally, execute the code to visualize the entity graph for the sample legal contract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentExtraction(entities=[Entity(id=1, subquote_string=['Agreement Contract', 'This Agreement is made and entered into on 2020-01-01'], entity_title='Agreement Contract', properties=[Property(key='Agreement Date', value='2020-01-01', resolved_absolute_value='2020-01-01')], dependencies=[1]), Entity(id=2, subquote_string=['Scope of Work', 'The Service Provider will deliver the software product to the Client 30 days after the agreement date'], entity_title='Scope of Work', properties=[Property(key='Delivery Date', value='30 days after the agreement date', resolved_absolute_value='2020-02-01')], dependencies=[1]), Entity(id=3, subquote_string=['Payment Terms', 'The total payment for the service is $50,000.', 'An initial payment of $10,000 will be made within 7 days of the the signed date.', 'The final payment will be due 45 days after [SignDate]'], entity_title='Payment Terms', properties=[Property(key='Total Payment', value='$50,000', resolved_absolute_value='$50,000'), Property(key='Initial Payment', value='$10,000', resolved_absolute_value='$10,000'), Property(key='Initial Payment Date', value='7 days of the the signed date', resolved_absolute_value='2020-01-08'), Property(key='Final Payment Date', value='45 days after [SignDate]', resolved_absolute_value='2020-02-15')], dependencies=[1]), Entity(id=4, subquote_string=['Confidentiality', 'The parties agree not to disclose any confidential information received from the other party for 3 months after the final payment date'], entity_title='Confidentiality', properties=[Property(key='Confidentiality Period', value='3 months after the final payment date', resolved_absolute_value='3 months after the final payment date')], dependencies=[3]), Entity(id=5, subquote_string=['Termination', 'The contract can be terminated with a 30-day notice, unless there are outstanding obligations that must be fulfilled after the [DeliveryDate]'], entity_title='Termination', properties=[Property(key='Termination Notice Period', value='30 days', resolved_absolute_value='30 days'), Property(key='Termination Date', value='outstanding obligations that must be fulfilled after the [DeliveryDate]', resolved_absolute_value='2020-02-01')], dependencies=[1])])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = \"\"\"\n",
    "Sample Legal Contract\n",
    "Agreement Contract\n",
    "\n",
    "This Agreement is made and entered into on 2020-01-01 by and between Company A (\"the Client\") and Company B (\"the Service Provider\").\n",
    "\n",
    "Article 1: Scope of Work\n",
    "\n",
    "The Service Provider will deliver the software product to the Client 30 days after the agreement date.\n",
    "\n",
    "Article 2: Payment Terms\n",
    "\n",
    "The total payment for the service is $50,000.\n",
    "An initial payment of $10,000 will be made within 7 days of the the signed date.\n",
    "The final payment will be due 45 days after [SignDate].\n",
    "\n",
    "Article 3: Confidentiality\n",
    "\n",
    "The parties agree not to disclose any confidential information received from the other party for 3 months after the final payment date.\n",
    "\n",
    "Article 4: Termination\n",
    "\n",
    "The contract can be terminated with a 30-day notice, unless there are outstanding obligations that must be fulfilled after the [DeliveryDate].\n",
    "\"\"\"  # Your legal contract here\n",
    "model = ask_ai(content)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PII Data Extraction and Scrubbing\n",
    "## Overview\n",
    "\n",
    "This example demonstrates the usage of OpenAI's ChatCompletion model for the extraction and scrubbing of Personally Identifiable Information (PII) from a document. The code defines Pydantic models to manage the PII data and offers methods for both extraction and sanitation.\n",
    "\n",
    "## Defining the Structures\n",
    "\n",
    "First, Pydantic models are defined to represent the PII data and the overall structure for PII data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# Define Schemas for PII data\n",
    "class Data(BaseModel):\n",
    "    index: int\n",
    "    data_type: str\n",
    "    pii_value: str\n",
    "\n",
    "\n",
    "class PIIDataExtraction(BaseModel):\n",
    "    \"\"\"\n",
    "    Extracted PII data from a document, all data_types should try to have consistent property names\n",
    "    \"\"\"\n",
    "\n",
    "    private_data: List[Data]\n",
    "\n",
    "    def scrub_data(self, content: str) -> str:\n",
    "        \"\"\"\n",
    "        Iterates over the private data and replaces the value with a placeholder in the form of\n",
    "        <{data_type}_{i}>\n",
    "        \"\"\"\n",
    "        for i, data in enumerate(self.private_data):\n",
    "            content = content.replace(data.pii_value, f\"<{data.data_type}_{i}>\")\n",
    "        return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting PII Data\n",
    "\n",
    "The Watsonx API is utilized to extract PII information from a given document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreswagner/Documents/GitHub/instructor/.venv/lib/python3.12/site-packages/ibm_watsonx_ai/foundation_models/inference/base_model_inference.py:723: UserWarning: Parameters [tool_choice] is/are not recognized and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted PII Data:\n",
      "{\"private_data\":[]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n{\"private_data\":[{\"index\":0,\"data_type\":\"Name\",\"pii_value\":\"John Doe\"},{\"index\":1,\"data_type\":\"Email\",\"pii_value\":\"john.doe@example.com\"},{\"index\":2,\"data_type\":\"Phone Number\",\"pii_value\":\"(555) 123-4567\"},{\"index\":3,\"data_type\":\"Address\",\"pii_value\":\"123 Main St, Anytown, USA\"},{\"index\":4,\"data_type\":\"Social Security Number\",\"pii_value\":\"123-45-6789\"}]}\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXAMPLE_DOCUMENT = \"\"\"\n",
    "# Fake Document with PII for Testing PII Scrubbing Model\n",
    "# (The content here)\n",
    "\"\"\"\n",
    "\n",
    "pii_data = instructor_client.messages.create(\n",
    "    response_model=PIIDataExtraction,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a world class PII scrubbing model, Extract the PII data from the following document\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": EXAMPLE_DOCUMENT,\n",
    "        },\n",
    "    ],\n",
    ")  # type: ignore\n",
    "\n",
    "print(\"Extracted PII Data:\")\n",
    "#> Extracted PII Data:\n",
    "print(pii_data.model_dump_json())\n",
    "\"\"\"\n",
    "{\"private_data\":[{\"index\":0,\"data_type\":\"Name\",\"pii_value\":\"John Doe\"},{\"index\":1,\"data_type\":\"Email\",\"pii_value\":\"john.doe@example.com\"},{\"index\":2,\"data_type\":\"Phone Number\",\"pii_value\":\"(555) 123-4567\"},{\"index\":3,\"data_type\":\"Address\",\"pii_value\":\"123 Main St, Anytown, USA\"},{\"index\":4,\"data_type\":\"Social Security Number\",\"pii_value\":\"123-45-6789\"}]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrubbing PII Data\n",
    "\n",
    "After extracting the PII data, the scrub_data method is used to sanitize the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrubbed Document:\n",
      "\n",
      "# Fake Document with PII for Testing PII Scrubbing Model\n",
      "# (The content here)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Fake Document with PII for Testing PII Scrubbing Model\\n# He was born on <date_0>. His social security number is <ssn_1>. He has been using the email address <email_2> for years, and he can always be reached at <phone_3>.\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Scrubbed Document:\")\n",
    "#> Scrubbed Document:\n",
    "print(pii_data.scrub_data(EXAMPLE_DOCUMENT))\n",
    "\"\"\"\n",
    "# Fake Document with PII for Testing PII Scrubbing Model\n",
    "# He was born on <date_0>. His social security number is <ssn_1>. He has been using the email address <email_2> for years, and he can always be reached at <phone_3>.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Tables using Watsonx.ai\n",
    "\n",
    "This post demonstrates how to use Python's type annotations and Watsonx new vision model to extract tables from images and convert them into markdown format. This method is particularly useful for data analysis and automation tasks.\n",
    "\n",
    "The full code is available on GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Custom Type for Markdown Tables\n",
    "\n",
    "First, we define a custom type, MarkdownDataFrame, to handle pandas DataFrames formatted in markdown. This type uses Python's Annotated and InstanceOf types, along with decorators BeforeValidator and PlainSerializer, to process and serialize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from typing import Annotated, Any\n",
    "from pydantic import BeforeValidator, PlainSerializer, InstanceOf, WithJsonSchema\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def md_to_df(data: Any) -> Any:\n",
    "    # Convert markdown to DataFrame\n",
    "    if isinstance(data, str):\n",
    "        return (\n",
    "            pd.read_csv(\n",
    "                StringIO(data),  # Process data\n",
    "                sep=\"|\",\n",
    "                index_col=1,\n",
    "            )\n",
    "            .dropna(axis=1, how=\"all\")\n",
    "            .iloc[1:]\n",
    "            .applymap(lambda x: x.strip())\n",
    "        )\n",
    "    return data\n",
    "\n",
    "\n",
    "MarkdownDataFrame = Annotated[\n",
    "    InstanceOf[pd.DataFrame],\n",
    "    BeforeValidator(md_to_df),\n",
    "    PlainSerializer(lambda df: df.to_markdown()),\n",
    "    WithJsonSchema(\n",
    "        {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The markdown representation of the table, each one should be tidy, do not try to join tables that should be seperate\",\n",
    "        }\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Table Class¶\n",
    "\n",
    "The Table class is essential for organizing the extracted data. It includes a caption and a dataframe, processed as a markdown table. Since most of the complexity is handled by the MarkdownDataFrame type, the Table class is straightforward!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Table(BaseModel):\n",
    "    caption: str\n",
    "    dataframe: MarkdownDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Tables from Images\n",
    "\n",
    "The extract_table function uses Watsonx vision model to process an image URL and extract tables in markdown format. We utilize the instructor library to patch the OpenAI client for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "import base64\n",
    "import requests\n",
    "from typing import Iterable\n",
    "from ibm_watsonx_ai.foundation_models.schema import TextChatParameters\n",
    "\n",
    "# Apply the patch to the client to support response_model\n",
    "# Also use MD_JSON mode since the vision model does not support any special structured output mode\n",
    "\n",
    "params = TextChatParameters(\n",
    "    temperature=1,\n",
    "    max_tokens=2000,\n",
    "    time_limit=600000\n",
    ")\n",
    "\n",
    "client = Model(\n",
    "    model_id='meta-llama/llama-3-2-90b-vision-instruct',\n",
    "    params=params,\n",
    "    credentials=Credentials(\n",
    "        api_key = os.environ.get(\"WATSONX_API_KEY\"),\n",
    "        url = os.environ.get(\"WATSONX_URL\")),\n",
    "    project_id= os.environ.get(\"WATSONX_PROJECT_ID\")\n",
    ")\n",
    "\n",
    "# Patch the client with Watsonx\n",
    "instructor_client=instructor.from_watsonx(\n",
    "    client=client,\n",
    "    mode=instructor.Mode.WATSONX_MD_JSON\n",
    ")\n",
    "\n",
    "\n",
    "def extract_table(url: str) -> Iterable[Table]:\n",
    "    url = url\n",
    "    response = requests.get(url)\n",
    "    encoded_string = base64.b64encode(response.content).decode('utf-8')\n",
    "\n",
    "    return instructor_client.messages.create(\n",
    "        response_model=Iterable[Table],\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Extract table from image.\"},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                        \"url\": \"data:image/jpeg;base64,\" + encoded_string,\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "\n",
    "url=\"https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png\"\n",
    "response = requests.get(url)\n",
    "encoded_string = base64.b64encode(response.content).decode('utf-8')\n",
    "question = \"Describe photo content\"\n",
    "\n",
    "params = TextChatParameters(\n",
    "    temperature=1,\n",
    "    max_tokens=2000,\n",
    "    time_limit=600000\n",
    ")\n",
    "\n",
    "client = Model(\n",
    "    model_id='meta-llama/llama-3-2-90b-vision-instruct',\n",
    "    params=params,\n",
    "    credentials=Credentials(\n",
    "        api_key = os.environ.get(\"WATSONX_API_KEY\"),\n",
    "        url = os.environ.get(\"WATSONX_URL\")),\n",
    "    project_id= os.environ.get(\"WATSONX_PROJECT_ID\")\n",
    ")\n",
    "\n",
    "\n",
    "messages = [\n",
    "  {\n",
    "    'role': 'user', \n",
    "    'content': 'As a genius expert, your task is to understand the content and provide the parsed objects in json that match the following json_schema:\\n\\n\\n        {\\n  \"$defs\": {\\n    \"Table\": {\\n      \"properties\": {\\n        \"caption\": {\\n          \"title\": \"Caption\",\\n          \"type\": \"string\"\\n        },\\n        \"dataframe\": {\\n          \"description\": \"The markdown representation of the table, each one should be tidy, do not try to join tables that should be seperate\",\\n          \"title\": \"Dataframe\",\\n          \"type\": \"string\"\\n        }\\n      },\\n      \"required\": [\\n        \"caption\",\\n        \"dataframe\"\\n      ],\\n      \"title\": \"Table\",\\n      \"type\": \"object\"\\n    }\\n  },\\n  \"description\": \"Correct segmentation of `Table` tasks\",\\n  \"properties\": {\\n    \"tasks\": {\\n      \"description\": \"Correctly segmented list of `Table` tasks\",\\n      \"items\": {\\n        \"$ref\": \"#/$defs/Table\"\\n      },\\n      \"title\": \"Tasks\",\\n      \"type\": \"array\"\\n    }\\n  },\\n  \"title\": \"IterableTable\",\\n  \"type\": \"object\"\\n}\\n\\n        Make sure to return an instance of the JSON, not the schema itself\\n'\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": question\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "          \"url\": \"data:image/jpeg;base64,\" + encoded_string,\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        'type': 'text',\n",
    "        'text': 'Return the correct JSON response within a ```json codeblock. not the JSON_SCHEMA'\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "response = client.chat(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chat-3584005f939b43d49f3cf9df7982b300',\n",
       " 'model_id': 'meta-llama/llama-3-2-90b-vision-instruct',\n",
       " 'model': 'meta-llama/llama-3-2-90b-vision-instruct',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': '**Step 1: Identify the image**\\n\\nThe image shows a table of the top 10 grossing apps in October 2023 (Ireland) for both Android and iOS platforms.\\n\\n**Step 2: Extract information from the image**\\n\\nThe table has two columns, one for Android and one for iOS, each showing the top 10 grossing apps. The apps are listed in order of their grossing amount, with the highest-grossing app at the top.\\n\\n**Step 3: Determine the correct JSON response**\\n\\nThe correct JSON response is an array of objects, where each object represents a task. Each task object should have two properties: \"caption\" and \"dataframe\". The \"caption\" property should be a string representing the caption of the table, and the \"dataframe\" property should be a string representing the markdown representation of the table.\\n\\n**Step 4: Return the correct JSON response**\\n\\nHere is the corrected JSON response:\\n\\n```\\n{\\n  \"tasks\": [\\n    {\\n      \"caption\": \"Top 10 grossing apps in October 2023 (Ireland)\",\\n      \"dataframe\": \"| Rank | App Name | Platform |\\\\n| --- | --- | --- |\\\\n| 1 | Google One | Android |\\\\n| 2 | Disney+ | Android |\\\\n| 3 | TikTok - Videos, Music & LIVE | Android |\\\\n| 4 | Candy Crush Saga | Android |\\\\n| 5 | Tinder: Dating, Chat & Friends | Android |\\\\n| 6 | Coin Master | Android |\\\\n| 7 | Roblox | Android |\\\\n| 8 | Bumble - Dating & Make Friends | Android |\\\\n| 9 | Royal Match | Android |\\\\n| 10 | Spotify: Music and Podcasts | Android |\\\\n| 1 | Tinder: Dating, Chat & Friends | iOS |\\\\n| 2 | Disney+ | iOS |\\\\n| 3 | YouTube: Watch, Listen, Stream | iOS |\\\\n| 4 | Audible: Audio Entertainment | iOS |\\\\n| 5 | Candy Crush Saga | iOS |\\\\n| 6 | TikTok - Videos, Music & LIVE | iOS |\\\\n| 7 | Bumble - Dating & Make Friends | iOS |\\\\n| 8 | Roblox | iOS |\\\\n| 9 | LinkedIn: Job Search & News | iOS |\\\\n| 10 | Duolingo - Language Lessons | iOS |\"\\n    }\\n  ]\\n}\\n```'},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'created': 1730856728,\n",
       " 'model_version': '3.2.0',\n",
       " 'created_at': '2024-11-06T01:32:27.964Z',\n",
       " 'usage': {'completion_tokens': 506,\n",
       "  'prompt_tokens': 6879,\n",
       "  'total_tokens': 7385},\n",
       " 'system': {'warnings': [{'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.',\n",
       "    'id': 'disclaimer_warning',\n",
       "    'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'}]}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Example\n",
    "\n",
    "In this example, we apply the method to extract data from an image showing the top grossing apps in Ireland for October 2023.\n",
    "\n",
    "<img src=\"https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "InstructorRetryException",
     "evalue": "'dict' object has no attribute 'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/instructor/instructor/retry.py:144\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[0m\n\u001b[1;32m    141\u001b[0m     response \u001b[38;5;241m=\u001b[39m update_total_usage(\n\u001b[1;32m    142\u001b[0m         response\u001b[38;5;241m=\u001b[39mresponse, total_usage\u001b[38;5;241m=\u001b[39mtotal_usage\n\u001b[1;32m    143\u001b[0m     )\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationError, JSONDecodeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/GitHub/instructor/instructor/process_response.py:153\u001b[0m, in \u001b[0;36mprocess_response\u001b[0;34m(response, response_model, stream, validation_context, strict, mode)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m--> 153\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# ? This really hints at the fact that we need a better way of\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# ? attaching usage data and the raw response to the model we return.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/instructor/instructor/function_calls.py:151\u001b[0m, in \u001b[0;36mOpenAISchema.from_response\u001b[0;34m(cls, completion, validation_context, strict, mode)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m Mode\u001b[38;5;241m.\u001b[39mWATSONX_MD_JSON:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_watsonx_md_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfinish_reason \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/GitHub/instructor/instructor/function_calls.py:363\u001b[0m, in \u001b[0;36mOpenAISchema.parse_watsonx_md_json\u001b[0;34m(cls, completion, validation_context, strict)\u001b[0m\n\u001b[1;32m    361\u001b[0m message \u001b[38;5;241m=\u001b[39m extract_json_from_codeblock(message)\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/instructor/.venv/lib/python3.12/site-packages/pydantic/main.py:625\u001b[0m, in \u001b[0;36mBaseModel.model_validate_json\u001b[0;34m(cls, json_data, strict, context)\u001b[0m\n\u001b[1;32m    624\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for IterableTable\n  Invalid JSON: expected value at line 5 column 20 [type=json_invalid, input_value='{\\n  \"tasks\": [\\n    {\\n...cation |\\n    }\\n  ]\\n}', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.9/v/json_invalid",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/instructor/instructor/retry.py:155\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[0m\n\u001b[1;32m    154\u001b[0m hooks\u001b[38;5;241m.\u001b[39memit_parse_error(e)\n\u001b[0;32m--> 155\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_reask_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/Documents/GitHub/instructor/instructor/reask.py:328\u001b[0m, in \u001b[0;36mhandle_reask_kwargs\u001b[0;34m(kwargs, mode, response, exception)\u001b[0m\n\u001b[1;32m    327\u001b[0m reask_function \u001b[38;5;241m=\u001b[39m functions\u001b[38;5;241m.\u001b[39mget(mode, reask_default)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreask_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexception\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/instructor/instructor/reask.py:255\u001b[0m, in \u001b[0;36mreask_default\u001b[0;34m(kwargs, response, exception)\u001b[0m\n\u001b[1;32m    254\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 255\u001b[0m reask_msgs \u001b[38;5;241m=\u001b[39m [dump_message(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)]\n\u001b[1;32m    256\u001b[0m reask_msgs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    257\u001b[0m     {\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m     }\n\u001b[1;32m    263\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'choices'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/instructor/instructor/retry.py:134\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[0m\n\u001b[1;32m    133\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/instructor/.venv/lib/python3.12/site-packages/tenacity/__init__.py:443\u001b[0m, in \u001b[0;36mBaseRetrying.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "File \u001b[0;32m~/Documents/GitHub/instructor/.venv/lib/python3.12/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/GitHub/instructor/.venv/lib/python3.12/site-packages/tenacity/__init__.py:419\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x12b06b1a0 state=finished raised AttributeError>]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstructorRetryException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Set logging to DEBUG\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#logging.basicConfig(level=logging.DEBUG)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tables \u001b[38;5;241m=\u001b[39m \u001b[43mextract_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[62], line 37\u001b[0m, in \u001b[0;36mextract_table\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     34\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m     35\u001b[0m encoded_string \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64encode(response\u001b[38;5;241m.\u001b[39mcontent)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstructor_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIterable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTable\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExtract table from image.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_url\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_url\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata:image/jpeg;base64,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mencoded_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/instructor/instructor/client.py:172\u001b[0m, in \u001b[0;36mInstructor.create\u001b[0;34m(self, response_model, messages, max_retries, validation_context, context, strict, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    162\u001b[0m     response_model: \u001b[38;5;28mtype\u001b[39m[T] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    169\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T \u001b[38;5;241m|\u001b[39m Any \u001b[38;5;241m|\u001b[39m Awaitable[T] \u001b[38;5;241m|\u001b[39m Awaitable[Any]:\n\u001b[1;32m    170\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_kwargs(kwargs)\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/instructor/instructor/patch.py:188\u001b[0m, in \u001b[0;36mpatch.<locals>.new_create_sync\u001b[0;34m(response_model, validation_context, context, max_retries, strict, hooks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m response_model, new_kwargs \u001b[38;5;241m=\u001b[39m handle_response_model(\n\u001b[1;32m    183\u001b[0m     response_model\u001b[38;5;241m=\u001b[39mresponse_model, mode\u001b[38;5;241m=\u001b[39mmode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    184\u001b[0m )\n\u001b[1;32m    186\u001b[0m new_kwargs \u001b[38;5;241m=\u001b[39m handle_templating(new_kwargs, context)\n\u001b[0;32m--> 188\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mretry_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/GitHub/instructor/instructor/retry.py:164\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    163\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetry error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InstructorRetryException(\n\u001b[1;32m    165\u001b[0m         e\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39m_exception,\n\u001b[1;32m    166\u001b[0m         last_completion\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m    167\u001b[0m         n_attempts\u001b[38;5;241m=\u001b[39mattempt\u001b[38;5;241m.\u001b[39mretry_state\u001b[38;5;241m.\u001b[39mattempt_number,\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;66;03m#! deprecate messages soon\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         messages\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    170\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m, []))\n\u001b[1;32m    171\u001b[0m         ),\n\u001b[1;32m    172\u001b[0m         create_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m    173\u001b[0m         total_usage\u001b[38;5;241m=\u001b[39mtotal_usage,\n\u001b[1;32m    174\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mInstructorRetryException\u001b[0m: 'dict' object has no attribute 'choices'"
     ]
    }
   ],
   "source": [
    "url=\"https://a.storyblok.com/f/47007/2400x2000/bf383abc3c/231031_uk-ireland-in-three-charts_table_v01_b.png\"\n",
    "# Set logging to DEBUG\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "tables = extract_table(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(caption='Top 10 grossing apps in October 2023 (Ireland)', dataframe=       Unnamed: 0                                          App Name   \\\n",
       "  Rank                                                                  \n",
       "  1                                          Google One: Productivity   \n",
       "  2                                            Disney+: Entertainment   \n",
       "  3                      TikTok - Videos, Music & LIVE: Entertainment   \n",
       "  4                                           Candy Crush Saga: Games   \n",
       "  5                 Tinder: Dating, Chat & Friends: Social networking   \n",
       "  6                                                Coin Master: Games   \n",
       "  7                                                    Roblox: Gaming   \n",
       "  8                            Bumble - Dating & Make Friends: Dating   \n",
       "  9                                                Royal Match: Games   \n",
       "  10                       Spotify: Music and Podcasts: Music & Audio   \n",
       " \n",
       "                 Category   \n",
       "  Rank                      \n",
       "  1           Productivity  \n",
       "  2          Entertainment  \n",
       "  3          Entertainment  \n",
       "  4                  Games  \n",
       "  5      Social networking  \n",
       "  6                  Games  \n",
       "  7                 Gaming  \n",
       "  8                 Dating  \n",
       "  9                  Games  \n",
       "  10         Music & Audio  )]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                                          App Name   \\\n",
      " Rank                                                                  \n",
      " 1                                          Google One: Productivity   \n",
      " 2                                            Disney+: Entertainment   \n",
      " 3                      TikTok - Videos, Music & LIVE: Entertainment   \n",
      " 4                                           Candy Crush Saga: Games   \n",
      " 5                 Tinder: Dating, Chat & Friends: Social networking   \n",
      " 6                                                Coin Master: Games   \n",
      " 7                                                    Roblox: Gaming   \n",
      " 8                            Bumble - Dating & Make Friends: Dating   \n",
      " 9                                                Royal Match: Games   \n",
      " 10                       Spotify: Music and Podcasts: Music & Audio   \n",
      "\n",
      "                Category   \n",
      " Rank                      \n",
      " 1           Productivity  \n",
      " 2          Entertainment  \n",
      " 3          Entertainment  \n",
      " 4                  Games  \n",
      " 5      Social networking  \n",
      " 6                  Games  \n",
      " 7                 Gaming  \n",
      " 8                 Dating  \n",
      " 9                  Games  \n",
      " 10         Music & Audio  \n"
     ]
    }
   ],
   "source": [
    "for table in tables:\n",
    "\n",
    "    print(table.dataframe)\n",
    "    \"\"\"\n",
    "           Android                                      ... Category\n",
    "     Rank                                               ...\n",
    "    1                                       Google One  ...      Social networking\n",
    "    2                                          Disney+  ...          Entertainment\n",
    "    3                    TikTok - Videos, Music & LIVE  ...          Entertainment\n",
    "    4                                 Candy Crush Saga  ...          Entertainment\n",
    "    5                   Tinder: Dating, Chat & Friends  ...                  Games\n",
    "    6                                      Coin Master  ...          Entertainment\n",
    "    7                                           Roblox  ...                 Dating\n",
    "    8                   Bumble - Dating & Make Friends  ...                  Games\n",
    "    9                                      Royal Match  ...               Business\n",
    "    10                     Spotify: Music and Podcasts  ...              Education\n",
    "\n",
    "    [10 rows x 4 columns]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>App Name</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Google One: Productivity</td>\n",
       "      <td>Productivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Disney+: Entertainment</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>TikTok - Videos, Music &amp; LIVE: Entertainment</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Candy Crush Saga: Games</td>\n",
       "      <td>Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>Tinder: Dating, Chat &amp; Friends: Social networking</td>\n",
       "      <td>Social networking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>Coin Master: Games</td>\n",
       "      <td>Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Roblox: Gaming</td>\n",
       "      <td>Gaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>Bumble - Dating &amp; Make Friends: Dating</td>\n",
       "      <td>Dating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>Royal Match: Games</td>\n",
       "      <td>Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>Spotify: Music and Podcasts: Music &amp; Audio</td>\n",
       "      <td>Music &amp; Audio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          App Name   \\\n",
       " Rank                                                                  \n",
       " 1                                          Google One: Productivity   \n",
       " 2                                            Disney+: Entertainment   \n",
       " 3                      TikTok - Videos, Music & LIVE: Entertainment   \n",
       " 4                                           Candy Crush Saga: Games   \n",
       " 5                 Tinder: Dating, Chat & Friends: Social networking   \n",
       " 6                                                Coin Master: Games   \n",
       " 7                                                    Roblox: Gaming   \n",
       " 8                            Bumble - Dating & Make Friends: Dating   \n",
       " 9                                                Royal Match: Games   \n",
       " 10                       Spotify: Music and Podcasts: Music & Audio   \n",
       "\n",
       "                Category   \n",
       " Rank                      \n",
       " 1           Productivity  \n",
       " 2          Entertainment  \n",
       " 3          Entertainment  \n",
       " 4                  Games  \n",
       " 5      Social networking  \n",
       " 6                  Games  \n",
       " 7                 Gaming  \n",
       " 8                 Dating  \n",
       " 9                  Games  \n",
       " 10         Music & Audio  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
